{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tg0deYVKQHl"
   },
   "source": [
    "# Project -1 : Build Sequential NLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hr4usxSKmqX",
    "outputId": "32c85a98-3cfa-4f5b-dd5e-f8ad8d8f794d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mv3Ww1A5Rbwx"
   },
   "source": [
    "# Refrences \n",
    "1) https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data\n",
    "2) https://radimrehurek.com/gensim/models/keyedvectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yZuug3ybRhMr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvoigV7NKwJF"
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRw3EO4lRf3G",
    "outputId": "c4bfc0b4-0990-4432-e204-9de448fb4b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    " #Import data set, consider top 10,000 most frequently used words...\n",
    " #So we will have words with highest frequency to lowest frequncy....in this consider top 10,000 words\n",
    "\n",
    " (X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyU8OaTrR6oA",
    "outputId": "878c7254-9f47-4584-8346-88ca95c1bfdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYRG6sI-SA6k",
    "outputId": "0372aac7-66a8-4cd8-84a4-e8fc12bc8cd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "k0tcfeBBYnVo"
   },
   "outputs": [],
   "source": [
    "#Will first merge train and test data to create complete set and then we can take train -test split as per our need\n",
    "X= np.concatenate((X_train,X_test),axis=0)\n",
    "Y = np.concatenate((y_train,y_test),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dq4WANdoOIjr"
   },
   "source": [
    "# Data Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hgM3N3KOPel",
    "outputId": "5c52f38c-6235-4628-cb36-a0b0dfe5668f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews 50000\n",
      "No of sentiments/labels [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of reviews\", X.shape[0])\n",
    "print(\"No of sentiments/labels\", np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-KS5iDcOztk",
    "outputId": "c56aded6-4bfc-452d-a04b-fcba695cf582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average no of words per review...\n",
      "234.75892\n"
     ]
    }
   ],
   "source": [
    "print(\"Average no of words per review...\")\n",
    "wordCountlst=[]\n",
    "for i in X:\n",
    "  wordCountlst.append(len(i))\n",
    "\n",
    "print(np.mean(wordCountlst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zReqSuEQ4ZZ",
    "outputId": "0fbede45-2253-4329-abd5-abed3d74d024"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2494"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(wordCountlst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXWPmETBRSp_"
   },
   "source": [
    "Lets check distribution of word count in below range\n",
    "- upto 300 \n",
    "- 301 to 450\n",
    "- 600 +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xzS92PKzRj5o"
   },
   "outputs": [],
   "source": [
    "wordCountlst300=[]\n",
    "wordCountlst450 =[]\n",
    "wordCountlst450plus = []\n",
    "\n",
    "for i in X :\n",
    "  if len(i) <= 300 :\n",
    "    wordCountlst300.append(len(i))\n",
    "  elif len(i) >300 and len(i) <=450 :\n",
    "    wordCountlst450.append(len(i))\n",
    "  elif  len(i) > 450 :\n",
    "    wordCountlst450plus.append(len(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "in91-sb8RSKF"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhdZRlqGTiwE",
    "outputId": "2837cb69-d8d4-46d9-cc42-f75eda25b978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Reviews with word count <=300 ====> 38583\n",
      "No of Reviews with word count >300 and <=450 ===> 6261\n",
      "No of Reviews with word count >450 ===> 5156\n"
     ]
    }
   ],
   "source": [
    "print(\"No of Reviews with word count <=300 ====>\", len(wordCountlst300))\n",
    "print(\"No of Reviews with word count >300 and <=450 ===>\",len(wordCountlst450))\n",
    "print(\"No of Reviews with word count >450 ===>\",len(wordCountlst450plus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQzX0T6ZRXQ5",
    "outputId": "4f93518a-2c5c-43cf-8b31-44a903edbdb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "index =  tf.keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYxAI5nNRYyd",
    "outputId": "bb03ace7-02b4-4bea-8f19-496f9645f3f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary count 88584\n"
     ]
    }
   ],
   "source": [
    "print(\"Total vocabulary count\", len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "801z-dY9TSGd"
   },
   "outputs": [],
   "source": [
    "# Lets see which are tope frequency words....need some processing\n",
    "index =  tf.keras.datasets.imdb.get_word_index()\n",
    "temp = dict([(value, key) for (key, value) in index.items()]) \n",
    "reviewlst =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1z4g54ihz-j"
   },
   "source": [
    "Decode Feature value to get original sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SlQS0DgHTyyg"
   },
   "outputs": [],
   "source": [
    "# Using word index from imdb, build orginal sentence in english for each row in X\n",
    "for x in X[0:]:\n",
    "  reviewlst.append(\" \".join( [temp.get(i-3, \"%\") for i in x]))       #replace unknown word with %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcHQ1kr9WbWn",
    "outputId": "b67809a0-14c0-4df3-9d6c-d2425f8f5893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviewlst) # total reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brgu06bfV-ij",
    "outputId": "d10a647d-c569-4196-a138-d41175c3229b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review.... % this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert % is an amazing actor and now the same being director % father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for % and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also % to the two little boy's that played the % of norman and paul they were just brilliant children are often left out of the % list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "Sentiment/Label... 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Review....\",reviewlst[0])\n",
    "print(\"Sentiment/Label...\", Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsDw88BbWxUm",
    "outputId": "5617021c-8bf6-4f76-f236-c63e56e29eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review.... % big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal % the hair is big lots of boobs % men wear those cut % shirts that show off their % sickening that men actually wore them and the music is just % trash that plays over and over again in almost every scene there is trashy music boobs and % taking away bodies and the gym still doesn't close for % all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
      "Sentiment/Label... 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Review....\",reviewlst[1])\n",
    "print(\"Sentiment/Label...\", Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-2wMN0SxXzWO"
   },
   "outputs": [],
   "source": [
    "t = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "t.fit_on_texts(reviewlst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HK2T31Gaizcq"
   },
   "source": [
    "Below code shows most word frequency count after converting input data into actual sentenses using word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1LWuSZlNp6b8"
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(t.word_counts,orient=\"index\",columns=['WordCount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "qFP-91GzaFhP",
    "outputId": "babfd130-b8e2-4b9e-b72f-90393f1c63f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>666757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>324337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>289379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>268079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paperhouse</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseketball</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>darkman</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carlito</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lanza</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9996 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             WordCount\n",
       "the             666757\n",
       "and             324337\n",
       "a               322800\n",
       "of              289379\n",
       "to              268079\n",
       "...                ...\n",
       "paperhouse          32\n",
       "baseketball         32\n",
       "darkman             32\n",
       "carlito             32\n",
       "lanza               32\n",
       "\n",
       "[9996 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sort_values('WordCount',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "qIEsl-0mPHTG",
    "outputId": "b2e0410f-60c4-4d78-c2f7-dd7f14082f19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f01b3707510>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 =pd.DataFrame(Y,index=Y[:],columns=['Sentiment'])\n",
    "df2['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOyjjAp_QMoc"
   },
   "source": [
    "The data is balanced dataset w.r.t. positive (1) and negative (0) sentiments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXAphUSRK5MU"
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34sSTvtliIb_"
   },
   "source": [
    "# Model-1 : Using glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "VebYoWjDQE0f"
   },
   "outputs": [],
   "source": [
    " # we have already downloaded data considering top 10,000 frequently used words\n",
    "max_features = 10000             \n",
    "# In the above section we have seen that no of reviews with word count <=540 is 38583+6261 =44844..which covers almost 90% of reviews\n",
    "maxlen = 450                  \n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YbBmcpLV92g"
   },
   "source": [
    "Lets do padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MbB0C7BAVyKX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ra_QQJefV_uM"
   },
   "outputs": [],
   "source": [
    "X_V1 = pad_sequences(X,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lm_EbljfWagW",
    "outputId": "926b7f83-c6cf-480a-97cd-86348c1c642f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_ew4mZVWTit",
    "outputId": "43a36b67-0e61-43a1-c475-91507c766fb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 450)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_V1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVZ5MsKmWoLX"
   },
   "source": [
    "The data is related to moview review...thus the words used are very common/generic for experessing postive and negative sentiment.\n",
    "\n",
    "So lets go with pre built embedding models for word embedding...such as glove as it is built with vast public data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "drfMIQHZWYCx"
   },
   "outputs": [],
   "source": [
    "# I am using file stored in my google drive\n",
    "embeddingFile = '/content/drive/MyDrive/LablFiles/SequenceNLP_Internal/glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uH3wUFV6Xfmt"
   },
   "outputs": [],
   "source": [
    "embeddingdic = {}\n",
    "\n",
    "for f in open(embeddingFile) :\n",
    "  word = f.split(\" \")[0]\n",
    "  embededval = f.split(\" \")[1:]\n",
    "  embededval = np.asarray(embededval,dtype='float32')\n",
    "  embeddingdic[word] =embededval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aleKzyGMYPad",
    "outputId": "09bef68e-7a95-4f03-afa5-45696cb8fd63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddingdic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-V1kpSLTZTFh"
   },
   "source": [
    "Lets check words randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNsgfHkzYQay",
    "outputId": "0f8f2bfd-2a9e-4f99-8b64-9cea2e1a6721"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.3074e-01,  4.0117e-01, -4.0785e-01,  1.5444e-01,  4.7782e-01,\n",
       "        2.0754e-01, -2.6951e-01, -3.4023e-01, -1.0879e-01,  1.0563e-01,\n",
       "       -1.0289e-01,  1.0849e-01, -4.9681e-01, -2.5128e-01,  8.4025e-01,\n",
       "        3.8949e-01,  3.2284e-01, -2.2797e-01, -4.4342e-01, -3.1649e-01,\n",
       "       -1.2406e-01, -2.8170e-01,  1.9467e-01,  5.5513e-02,  5.6705e-01,\n",
       "       -1.7419e+00, -9.1145e-01,  2.7036e-01,  4.1927e-01,  2.0279e-02,\n",
       "        4.0405e+00, -2.4943e-01, -2.0416e-01, -6.2762e-01, -5.4783e-02,\n",
       "       -2.6883e-01,  1.8444e-01,  1.8204e-01, -2.3536e-01, -1.6155e-01,\n",
       "       -2.7655e-01,  3.5506e-02, -3.8211e-01, -7.5134e-04, -2.4822e-01,\n",
       "        2.8164e-01,  1.2819e-01,  2.8762e-01,  1.4440e-01,  2.3611e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingdic['this']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3r6CdM_nYS1p",
    "outputId": "dd4ee03c-9e20-4d43-c9b5-26d07dfaa582"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54623  ,  1.2042   , -1.1288   , -0.1325   ,  0.95529  ,\n",
       "        0.040524 , -0.47863  , -0.3397   , -0.28056  ,  0.71761  ,\n",
       "       -0.53691  , -0.0045698,  0.73217  ,  0.12101  ,  0.28093  ,\n",
       "       -0.088097 ,  0.59733  ,  0.55264  ,  0.056646 , -0.50247  ,\n",
       "       -0.63204  ,  1.1439   , -0.31053  ,  0.1263   ,  1.3155   ,\n",
       "       -0.52444  , -1.5041   ,  1.158    ,  0.68795  , -0.85051  ,\n",
       "        2.3236   , -0.41789  ,  0.44519  , -0.019216 ,  0.28969  ,\n",
       "        0.53258  , -0.023008 ,  0.58958  , -0.72397  , -0.85216  ,\n",
       "       -0.17761  ,  0.14432  ,  0.40658  , -0.52003  ,  0.09081  ,\n",
       "        0.082961 , -0.021975 , -1.6214   ,  0.34579  , -0.010919 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingdic['beautiful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_ayxo_KYflR",
    "outputId": "49a33384-6afe-4933-fc8d-6a9201b63d18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.17981 , -0.40407 , -0.1653  , -0.60687 , -0.39656 ,  0.12688 ,\n",
       "       -0.053049,  0.38024 , -0.51008 ,  0.46593 , -0.30818 ,  0.79362 ,\n",
       "       -0.85766 , -0.25143 ,  1.0448  ,  0.18628 ,  0.13688 ,  0.092588,\n",
       "       -0.2236  , -0.13604 , -0.19482 ,  0.057702,  0.56133 ,  0.24823 ,\n",
       "        0.627   , -1.8437  , -1.2573  ,  0.64482 ,  1.2787  , -0.29522 ,\n",
       "        3.0493  ,  0.62079 ,  0.90369 , -0.030099, -0.13091 ,  0.30525 ,\n",
       "       -0.070138, -0.12912 ,  0.72277 , -0.79774 , -0.70277 ,  0.038009,\n",
       "        0.27192 ,  0.35679 ,  0.26493 ,  0.13037 , -0.01369 ,  0.33713 ,\n",
       "        0.99956 ,  0.72031 ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingdic['bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ev__3uzZYGf",
    "outputId": "6ece7e9b-f0c7-44cc-d1f9-e0b114015321"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.7049e-01, -7.7854e-03, -7.0766e-01, -3.1785e-01,  8.9493e-01,\n",
       "       -1.6128e-02, -6.7149e-02,  1.5765e-01, -4.9832e-01,  2.5845e-01,\n",
       "        1.0943e-01,  3.6728e-01, -1.4843e-01,  6.3286e-02,  2.0832e-01,\n",
       "        4.5920e-01,  7.1781e-01,  2.2772e-01, -1.5349e-03, -9.3093e-01,\n",
       "       -8.0048e-01,  4.6714e-01,  4.1571e-01,  1.7572e-01,  1.0876e+00,\n",
       "       -1.6116e+00, -7.0943e-01,  8.3772e-01,  6.7081e-01,  1.8139e-01,\n",
       "        3.9899e+00, -1.0270e-01,  4.3900e-01, -6.7926e-01,  1.1861e-01,\n",
       "       -2.0182e-01, -8.1603e-02,  9.0739e-01, -5.2258e-01, -4.8426e-01,\n",
       "       -3.1326e-01,  1.0325e-01,  1.3036e-01,  3.5115e-01,  3.7593e-01,\n",
       "        6.4388e-02, -2.2590e-01,  7.9125e-02,  1.2573e-01,  8.3939e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingdic['very']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1cBYGvKaCJ0"
   },
   "source": [
    "Lets create weight matrix for words in the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjOM-dvLaeAU",
    "outputId": "37512b65-408b-4dd5-990e-1c710345bdba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88585\n"
     ]
    }
   ],
   "source": [
    "NoofWords = len(tf.keras.datasets.imdb.get_word_index()) +1\n",
    "#NoofWords = len(t.word_index)+1\n",
    "print(NoofWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "TyPTBp0BaRwb"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((NoofWords,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "lJ5iOLskaqjZ"
   },
   "outputs": [],
   "source": [
    "for word, i in tf.keras.datasets.imdb.get_word_index().items() :\n",
    "  embedding_vector = embeddingdic.get(word)\n",
    "  if embedding_vector is not None :\n",
    "    embedding_matrix[i]  =   embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKZhDY9Pa_uh",
    "outputId": "ec2fbb48-0845-46ff-92ee-b65a4da122e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88585, 50)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOJxCpFJbDdh",
    "outputId": "7931cf29-5643-4cd1-c6fe-b94c5336706f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.18000013e-01,  2.49679998e-01, -4.12420005e-01,  1.21699996e-01,\n",
       "        3.45270008e-01, -4.44569997e-02, -4.96879995e-01, -1.78619996e-01,\n",
       "       -6.60229998e-04, -6.56599998e-01,  2.78430015e-01, -1.47670001e-01,\n",
       "       -5.56770027e-01,  1.46579996e-01, -9.50950012e-03,  1.16579998e-02,\n",
       "        1.02040000e-01, -1.27920002e-01, -8.44299972e-01, -1.21809997e-01,\n",
       "       -1.68009996e-02, -3.32789987e-01, -1.55200005e-01, -2.31309995e-01,\n",
       "       -1.91809997e-01, -1.88230002e+00, -7.67459989e-01,  9.90509987e-02,\n",
       "       -4.21249986e-01, -1.95260003e-01,  4.00710011e+00, -1.85939997e-01,\n",
       "       -5.22870004e-01, -3.16810012e-01,  5.92130003e-04,  7.44489999e-03,\n",
       "        1.77780002e-01, -1.58969998e-01,  1.20409997e-02, -5.42230010e-02,\n",
       "       -2.98709989e-01, -1.57490000e-01, -3.47579986e-01, -4.56370004e-02,\n",
       "       -4.42510009e-01,  1.87849998e-01,  2.78489990e-03, -1.84110001e-01,\n",
       "       -1.15139998e-01, -7.85809994e-01])"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJSg11XOhJKp"
   },
   "source": [
    "Split the data into train, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "jYOCL7DzbI5v"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "rom32F64hP1t"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_V1,Y,test_size=0.2,random_state=65,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_GCcWZ7hdgV",
    "outputId": "11a225aa-4e0a-46df-f365-783841b0d65c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 450)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4tyf0IsRhex9",
    "outputId": "4c44e25b-544e-4b68-ad5c-e9bb54502cfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 450)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "x1_7wef_hhK1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "2J5oREQ_hqnV"
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "SuBnTr5yhrM3"
   },
   "outputs": [],
   "source": [
    "model.add(Embedding(NoofWords,embedding_size,weights=[embedding_matrix], input_length=maxlen))\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(1,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "vSrfmUSxiWTp"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaWRAZ1miY4B",
    "outputId": "03feacf6-b570-4d37-e4c7-f14fe9949ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 450, 50)           4429250   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 450, 256)          314368    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               29491456  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 34,276,803\n",
      "Trainable params: 34,276,547\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "rRhK4AtTib7l"
   },
   "outputs": [],
   "source": [
    "batchsize = 512\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "lznDDdgqijkJ",
    "outputId": "9e8c7181-3cec-4c96-bf74-cc4916c98960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "79/79 [==============================] - 1029s 13s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/8\n",
      "79/79 [==============================] - 1018s 13s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/8\n",
      "79/79 [==============================] - 1010s 13s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/8\n",
      "79/79 [==============================] - 1008s 13s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/8\n",
      "79/79 [==============================] - 1041s 13s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/8\n",
      "56/79 [====================>.........] - ETA: 4:37 - loss: 0.0000e+00 - accuracy: 0.5009"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-b8fced5a76da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batchsize, epochs= epochs,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-omXcG_4iWnn"
   },
   "source": [
    "# Model-1 : Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUwZvP-Eic1e"
   },
   "source": [
    "Tried different values of epochs, batch size but the accuracy and validation accuracy is not going beyond 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjlBfc8qixGR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFor0HZriywR"
   },
   "source": [
    "# Model-2 : Using gensim library, Word2Vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EHYjHzVkix8M"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZOJliqgjdfD"
   },
   "source": [
    "Load already trained gensim embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "GY0oaUZLQH4C"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ZWhkyGBXPOoB"
   },
   "outputs": [],
   "source": [
    "modelPath ='/content/drive/MyDrive/LablFiles/SequenceNLP_Internal/word2vec-google-news-300.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmuzU89EStMq",
    "outputId": "aa6c6a54-ffc7-4b54-d31f-9370cbbc7593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/LablFiles/SequenceNLP_Internal\n"
     ]
    }
   ],
   "source": [
    "cd '/content/drive/MyDrive/LablFiles/SequenceNLP_Internal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCPulQMgmgGy",
    "outputId": "281ab1fe-2428-4b5d-d12c-7acb824cc643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vec = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iIVfWfEqpmP"
   },
   "source": [
    "Store doanloaded file in some folder in google drive so that next time \n",
    "we can load model directly from file instead of downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LB7n65KCqZ9Z"
   },
   "outputs": [],
   "source": [
    "# Code is commented after copying file to some permanant folder\n",
    "#!cp '/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz' '/content/drive/MyDrive/LablFiles/SequenceNLP_Internal/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfC-at4UlLZp",
    "outputId": "a2a2fa1d-c8c2-4a13-9a47-29bbd5883b96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7f01b4d42150>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGIJ1KqMnvd5",
    "outputId": "aeb74f55-b96c-4e63-ad99-f6ae74675ab0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "embedding_size = word2vec.wv.syn0.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMOcQ5YmrUzK",
    "outputId": "9276a014-cd3f-4673-eb3d-f5f1e1084bdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "NOsnP7aiUT39"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Lpd1tcvVoEGe"
   },
   "outputs": [],
   "source": [
    " # we have already downloaded data considering top 10,000 frequently used words\n",
    "max_features = 10000             \n",
    "# In the above section we have seen that no of reviews with word count <=300 is 38583\n",
    "# So lets consider 300 words\n",
    "maxlen = 300 \n",
    "X_V1 = pad_sequences(X,maxlen=maxlen)    \n",
    "x_train, x_test, y_train, y_test = train_test_split(X_V1,Y,test_size=0.2,random_state=78,stratify=Y)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1lw6EPsUn4Yt"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((max_features + 1, embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noYGUnpYosqs",
    "outputId": "f5b6cacd-e9c6-4e00-f587-38accfc7520f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
    "    if i > max_features:\n",
    "        break\n",
    "    #if word in word2vec.key_to_index :\n",
    "    if word in word2vec.wv.vocab :\n",
    "        embedding_vector = word2vec.wv[word]\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0mjg3SWsSOG",
    "outputId": "3c09fd01-6e27-4934-e7d3-232b4c63a13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 300)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "c-kpxG6MsoEe"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout, Flatten, BatchNormalization\n",
    "\n",
    "model2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "GrgJUwEas9s6"
   },
   "outputs": [],
   "source": [
    "model2.add(Embedding(max_features+1,embedding_size,weights=[embedding_matrix], input_length=maxlen,trainable=False))\n",
    "model2.add(LSTM(128,return_sequences=True))\n",
    "model2.add(Dropout(0.15))\n",
    "model2.add(Dense(64,activation='tanh'))\n",
    "model2.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dnvBPZmm3Xd",
    "outputId": "2942249d-8755-478e-a027-83345a89f9d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 300)          3000300   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300, 128)          219648    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300, 64)           8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300, 1)            65        \n",
      "=================================================================\n",
      "Total params: 3,228,269\n",
      "Trainable params: 227,969\n",
      "Non-trainable params: 3,000,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ZjtlV220uENW"
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',metrics=['accuracy'], loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "lbH0TkxmuQAL"
   },
   "outputs": [],
   "source": [
    "batchsize = 128\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giRE4UR7uLQJ",
    "outputId": "45a5556b-e909-4cce-9858-55f7ee86a76e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 463s 1s/step - loss: 0.6866 - accuracy: 0.5353 - val_loss: 0.6906 - val_accuracy: 0.5146\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 456s 1s/step - loss: 0.6756 - accuracy: 0.5656 - val_loss: 0.6752 - val_accuracy: 0.5606\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 470s 2s/step - loss: 0.6595 - accuracy: 0.5888 - val_loss: 0.6511 - val_accuracy: 0.5911\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 479s 2s/step - loss: 0.6375 - accuracy: 0.6090 - val_loss: 0.6236 - val_accuracy: 0.6238\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 475s 2s/step - loss: 0.6193 - accuracy: 0.6223 - val_loss: 0.6226 - val_accuracy: 0.6173\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train, y_train, batch_size=batchsize, epochs= epochs,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "grvTVH_hVMlU"
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "model2.save('/content/drive/MyDrive/LablFiles/SequenceNLP_Internal/Project1_model2.h5')\n",
    "\n",
    "#from keras.models import load_model\n",
    "#loaded_model = load_model('/content/drive/MyDrive/LablFiles/SequenceNLP_Internal/Project1_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "XewJYlhJ5jv7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "lw5DQrs900jr"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model2_1 = load_model('/content/drive/MyDrive/LablFiles/SequenceNLP_Internal/Project1_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3_JzaUWE-Vd",
    "outputId": "693a53f9-6087-4053-d5d4-86551323d4d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 76s 188ms/step - loss: 0.6226 - accuracy: 0.6173\n"
     ]
    }
   ],
   "source": [
    "result = model2_1.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tU2wQYmEFC7x",
    "outputId": "74b02ab5-3940-471f-df49-f5a4fd3f6b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss and Accuracy [0.6225565671920776, 0.6173170208930969]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss and Accuracy\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R50ThG48Fzqg",
    "outputId": "967ca280-2e5e-43a9-dc6d-b709eb8ea45e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy 0.5841941833496094\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy\",np.mean(history2.history[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6hrj8S73cF2"
   },
   "source": [
    "Lets do prection on some random samples from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "8700CYJvGXor"
   },
   "outputs": [],
   "source": [
    "pred = model2_1.predict(X_V1[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "huF3oFDl1zip"
   },
   "outputs": [],
   "source": [
    "y_pred = (pred >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "CNdjGcTx15wJ"
   },
   "outputs": [],
   "source": [
    "dfres = pd.DataFrame({\"sentiment\": y_pred.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ngXSxyH2JLf",
    "outputId": "f55e453c-4ea0-4aa1-e653-634c5bd78fbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    276\n",
       "0     24\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXUzh44I2LdF",
    "outputId": "34779b0a-9c80-4dbd-ecc9-2bc97de4b4e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "oIF4uY7h2a27"
   },
   "outputs": [],
   "source": [
    "pred = model2_1.predict(X_V1[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "kUmTwK692sCQ"
   },
   "outputs": [],
   "source": [
    "y_pred = (pred >= 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "XKf5CAaf2wi2"
   },
   "outputs": [],
   "source": [
    "dfres = pd.DataFrame({\"sentiment\": y_pred.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNcyFtlG2yhh",
    "outputId": "0dac3412-8c5e-4a1b-f12e-5c0182250682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    135\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEo8rFR721Ws",
    "outputId": "9afebad4-0132-4401-fa13-65b4276c8e12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGpGWUMU5R3S"
   },
   "source": [
    "Lets do some prediciton on the \"reviewlst\" which was created in above section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FF0d5IYo5qaW",
    "outputId": "35a38191-8b5c-4af6-f781-aec5b3efd2cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review.... % this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert % is an amazing actor and now the same being director % father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for % and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also % to the two little boy's that played the % of norman and paul they were just brilliant children are often left out of the % list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "Sentiment/Label... 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Review....\",reviewlst[0])\n",
    "print(\"Sentiment/Label...\", Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "EQrLIDTl5NOR"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "aXyOZjKO5gm5"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(reviewlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "sDPO6YDH5wVX"
   },
   "outputs": [],
   "source": [
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "qG9sIrf655qx"
   },
   "outputs": [],
   "source": [
    "x_new_train = tokenizer.texts_to_sequences(reviewlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "GXkU6U7o6EeK"
   },
   "outputs": [],
   "source": [
    "x_new_train = pad_sequences(x_new_train, maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "cCJy9g4V6PtU"
   },
   "outputs": [],
   "source": [
    "preds = model2_1.predict(x_new_train[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqKmzZiW6pjN",
    "outputId": "2976d72e-4b01-4865-c565-43224d9449e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% when philo vance edmund lowe is standing % on the edge of a balcony high above the city apparently % and just about to step to his death it immediately reminded me of a nearly identical scene in another film made nine years later the woman in green in which sherlock holmes basil % is similarly about to % himself into space while being % br br happily both philo vance and sherlock holmes survive these attempts at murder by % criminals exciting cinematic suspense in both these scenes when will they learn you can't cloud the minds of great fictional detectives\n",
      "predicted sentiment : positive\n",
      "correct sentiment : positive\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,50)\n",
    "\n",
    "print(reviewlst[n])\n",
    "\n",
    "if preds[n].any() > 0.5:\n",
    "  print('predicted sentiment : positive')\n",
    "else: \n",
    "  print('precicted sentiment : negative')\n",
    "\n",
    "if (Y[n] == 1):\n",
    "  print('correct sentiment : positive')\n",
    "else:\n",
    "  print('correct sentiment : negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsRn_xOQ7fG_",
    "outputId": "fc5588f1-696d-4719-919d-b09243decfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% b movie at best sound effects are pretty good lame concept decent execution i suppose it's a rental br br you put some % oil in your mouth to save you from de poison % you cut de bite and suck out de % you gonna be ok tommy br br you stay by the % when agent harris calls you get me give me a fire % br br weapons we need weapons where's the % all we have is this % br br dr price is the snake expert br br local % can handle the occasional % alert every er in the % city area\n",
      "predicted sentiment : positive\n",
      "correct sentiment : negative\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,50)\n",
    "\n",
    "print(reviewlst[n])\n",
    "\n",
    "if preds[n].any() > 0.5:\n",
    "  print('predicted sentiment : positive')\n",
    "else: \n",
    "  print('precicted sentiment : negative')\n",
    "\n",
    "if (Y[n] == 1):\n",
    "  print('correct sentiment : positive')\n",
    "else:\n",
    "  print('correct sentiment : negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWwi9RVc7NNW",
    "outputId": "a44428cd-8a56-47a5-f4fd-cfea9df33e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% i have only had the luxury of seeing this movie once when i was rather young so much of the movie is % in trying to remember it however i can say it was not as funny as a movie called killer tomatoes should have been and the most memorable things from this movie are the song and the scene with the elderly couple talking about poor timmy other than that the movie is really just scenes of little tomatoes and big tomatoes rolling around and people acting scared and overacting as people should do in a movie of this type however just having a very silly premise and a catchy theme song do not a good comedy make granted this movie is supposed to be a b movie nothing to be taken seriously however you should still make jokes that are funny and not try to % a mildly amusing premise into a full % movie perhaps a short would have been fine as the trailer showing the elderly couple mentioned above and a man desperately trying to gun down a larger % was actually pretty good the trailer itself looked like a mock trailer but no they indeed made a full movie and a rather weak one at that\n",
      "predicted sentiment : positive\n",
      "correct sentiment : negative\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,50)\n",
    "\n",
    "print(reviewlst[n])\n",
    "\n",
    "if preds[n].any() > 0.5:\n",
    "  print('predicted sentiment : positive')\n",
    "else: \n",
    "  print('precicted sentiment : negative')\n",
    "\n",
    "if (Y[n] == 1):\n",
    "  print('correct sentiment : positive')\n",
    "else:\n",
    "  print('correct sentiment : negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guHiNLro7iOu",
    "outputId": "8f1f5038-8b71-420b-df99-8cc19536b885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% bela lugosi appeared in several of these low budget % for % studios in the 1940's and the corpse % is one of the better ones br br bela plays a mad scientist who kidnaps young brides and kills them and then % fluid from their bodies so he can keep his % wife looking young after a reporter and a doctor stay the night at his home and discover he is responsible for the % deaths the following morning they report these murders to the police and the mad scientist is shot and drops dead shortly afterwards br br you have got almost everything in this movie the % % consist of an old % a % and dwarf her sons a % and spooky % in % house bela and his wife find they sleep better in % rather than % in the movie br br the corpse % is worth a look especially for bela lugosi fans great fun br br rating 3 stars out of 5\n",
      "predicted sentiment : positive\n",
      "correct sentiment : positive\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,50)\n",
    "\n",
    "print(reviewlst[n])\n",
    "\n",
    "if preds[n].any() > 0.5:\n",
    "  print('predicted sentiment : positive')\n",
    "else: \n",
    "  print('precicted sentiment : negative')\n",
    "\n",
    "if (Y[n] == 1):\n",
    "  print('correct sentiment : positive')\n",
    "else:\n",
    "  print('correct sentiment : negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2T3O6JL7qME",
    "outputId": "4c26c8c5-b68b-4b7d-e1b8-6496f981b27f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert % is an amazing actor and now the same being director % father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for % and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also % to the two little boy's that played the % of norman and paul they were just brilliant children are often left out of the % list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "predicted sentiment : positive\n",
      "correct sentiment : positive\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,50)\n",
    "\n",
    "print(reviewlst[n])\n",
    "\n",
    "if preds[n].any() > 0.5:\n",
    "  print('predicted sentiment : positive')\n",
    "else: \n",
    "  print('precicted sentiment : negative')\n",
    "\n",
    "if (Y[n] == 1):\n",
    "  print('correct sentiment : positive')\n",
    "else:\n",
    "  print('correct sentiment : negative')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pgp_aiml_feb20_SeqNLP_R10_Project-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
