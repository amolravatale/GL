{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"2c. Sentiment_Analysis_Glove_Embedding_LSTM.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["mQKm7K78KMQa","40sSeDoWKMQx","2GgPOuSzKMRA","fKmVWM5pKMRF","m7CMlSVYCHNA","UTZqcuaqB2cl","j_aH5TX5KMSA"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mQKm7K78KMQa"},"source":["### Connect to Kaggle"]},{"cell_type":"markdown","metadata":{"id":"IS0axMJDKrph"},"source":["We will be using data available on Kaggle platform for this exercise. The data is available at https://www.kaggle.com/c/word2vec-nlp-tutorial/data. We will first connect Colab to Kaggle. Instructions for downloading kaggle data to Colab can be found [in this post](https://towardsdatascience.com/setting-up-kaggle-in-google-colab-ebb281b61463)."]},{"cell_type":"code","metadata":{"id":"sGWPxBNMK5XW"},"source":["!pip install kaggle --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ii1tX4nQK71e"},"source":["#Make a directory for Kaggle\n","!mkdir .kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxnI1KLhLJ_J"},"source":["#Connect Google drive to colab\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVSzOh4gLOjT"},"source":["#Copy kaggle.json file. Change gdrive folder based on where you have saved your json file from Kaggle\n","!cp '/gdrive/My Drive/AI-ML/Machine-Learning/Code/Utilities/kaggle.json' /content/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8EXjrP_LZsO"},"source":["#Check if json file is there\n","!ls -l /content/.kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DexRyePCLdFw"},"source":["!mkdir ~/.kaggle\n","!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n","!kaggle config set -n path -v{/content}\n","!chmod 600 /root/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQ2IP5KOLv3l"},"source":["Verify Kaggle connection"]},{"cell_type":"code","metadata":{"id":"e1l26nwNLvD4"},"source":["!kaggle datasets list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qaEMdD8mL0ZT"},"source":["#### Download Movie Reviews data"]},{"cell_type":"code","metadata":{"id":"repGnUbKL4DI"},"source":["!kaggle competitions download -c word2vec-nlp-tutorial -p /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFfwUE0ZMPXY"},"source":["#Confirm data has been downloaded\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CIxtVF3NKMQj"},"source":["Import the dataset as pandas dataframe"]},{"cell_type":"code","metadata":{"id":"GfiVR8PzKMQe"},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5K8RSBNXKMQn"},"source":["df = pd.read_csv('labeledTrainData.tsv.zip',header=0, delimiter=\"\\t\", quoting=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P7Ds7i3TUGCr"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXwe99hqULiJ"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q12_oUDIIC-k"},"source":["df.loc[0, 'review']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"45uxRF4rKMQq"},"source":["Split Data into Training and Test Data"]},{"cell_type":"code","metadata":{"id":"cwNZ5XEpKMQq"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-RNaPq2KMQt"},"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    df['review'],\n","    df['sentiment'],\n","    test_size=0.2, \n","    random_state=42\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IdMWitcdByBs"},"source":["X_train.shape, X_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"40sSeDoWKMQx"},"source":["### Build the Tokenizer"]},{"cell_type":"code","metadata":{"id":"AGM55RRUM3fN"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNB6T0EVKMQ6"},"source":["desired_vocab_size = 10000 #Vocablury size\n","t = tf.keras.preprocessing.text.Tokenizer(num_words=desired_vocab_size,oov_token='OOV') # num_words -> Vocablury size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t65mfe_2KMQ8"},"source":["#Fit tokenizer with actual training data\n","t.fit_on_texts(X_train.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6N7cgYEvVGzB"},"source":["#Vocabulary\n","t.word_index"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2GgPOuSzKMRA"},"source":["### Prepare Training and Test Data"]},{"cell_type":"markdown","metadata":{"id":"8o8fG3FtKMRA"},"source":["Get the word index for each of the word in the review"]},{"cell_type":"code","metadata":{"id":"G9m65RFCVXCd"},"source":["X_train[0:1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNQIpYPKKMRB"},"source":["X_train = t.texts_to_sequences(X_train.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xh1nDZFDVlB8"},"source":["print(X_train[0:1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Gix3lNmKMRD"},"source":["X_test = t.texts_to_sequences(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hb9z28TZKMRF"},"source":["How many words in each review?"]},{"cell_type":"code","metadata":{"id":"O7maQ5kpxdfI"},"source":["len(X_train[1000])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fKmVWM5pKMRF"},"source":["### Pad Sequences - Important"]},{"cell_type":"code","metadata":{"id":"h5YfEUx2KMRI"},"source":["#Define maximum number of words to consider in each review\n","max_review_length = 300"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeJeFjogKMRM"},"source":["#Pad training and test reviews\n","X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n","                                                        maxlen=max_review_length,\n","                                                        padding='pre', truncating='post')\n","X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, \n","                                                       maxlen=max_review_length, \n","                                                       padding='pre', truncating='post')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4GLCWBOlztU"},"source":["X_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QJqX-Z5wL-W"},"source":["X_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HVteHr5IzS4I"},"source":["X_train[200]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m7CMlSVYCHNA"},"source":["### Download Glove model\n","\n","Check out this [link](https://nlp.stanford.edu/projects/glove/) for available pre-trained Glove models from Standord.\n","\n","https://nlp.stanford.edu/projects/glove/"]},{"cell_type":"code","metadata":{"id":"NkeTTZN54Dcm"},"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7nx5iFr74KCQ"},"source":["#Check if embeddings have been downloaded\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JMx5vyB14pGk"},"source":["#unzip the file, we get multiple embedding files. We can use either one of them\n","!unzip glove.6B.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aP_jerX4s8n_"},"source":["We have 4 models in this zip file. '50d' in the filename means that embedding size is 50 (100d means embedding size 100). We can use any one of the 4 models."]},{"cell_type":"code","metadata":{"id":"kQRcZqc354yr"},"source":["!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BO7MERRT5Bec"},"source":["### Convert Glove to Word2Vec format"]},{"cell_type":"code","metadata":{"id":"Rq0NouVy5Nb4"},"source":["#Install Gensim\n","!pip install gensim --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0yR0q8uz5ZC8"},"source":["from gensim.scripts.glove2word2vec import glove2word2vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OiCu6QGz5jJA"},"source":["#Glove file - we are using model with 50 embedding size\n","glove_input_file = 'glove.6B.50d.txt'\n","\n","#Name for word2vec file\n","word2vec_output_file = 'glove.6B.50d.txt.word2vec'\n","\n","#Convert Glove embeddings to Word2Vec embeddings\n","glove2word2vec(glove_input_file, word2vec_output_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVRODxmI6QgJ"},"source":["!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UTZqcuaqB2cl"},"source":["### Get Embeddings (from Pre-trained model)"]},{"cell_type":"markdown","metadata":{"id":"sCVQv-FgtrCp"},"source":["Pre-trained Glove model has 400,000 unique words (Vocabulary size). We do not need all the words. Moreover, we have to arrange word embeddings according to word index created by our tokenizers above. So we will extract word embeddings for only the words that we are interested in."]},{"cell_type":"code","metadata":{"id":"o1ycexOAB4qD"},"source":["from gensim.models import Word2Vec, KeyedVectors"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnfmU0U7B1ja"},"source":["# Load pretrained Glove model (in word2vec form)\n","glove_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SbgVAzAPDl1O"},"source":["#Embedding length based on selected model - we are using 50d here.\n","embedding_vector_length = 50"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i_OwTH8duDX0"},"source":["Initialize a embedding matrix which we will populate for our vocabulary words."]},{"cell_type":"code","metadata":{"id":"HPNcZC9PEA8v"},"source":["#Initialize embedding matrix\n","embedding_matrix = np.zeros((desired_vocab_size + 1, embedding_vector_length))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgRtfyRzi25X"},"source":["embedding_matrix.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yu0SnwlguM4e"},"source":["Load word vectors for each word in our vocabulary from from Glove pre-trained model"]},{"cell_type":"code","metadata":{"id":"mufDrkM-EKlK"},"source":["for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n","    if i > (desired_vocab_size+1):\n","        break\n","    try:\n","        embedding_vector = glove_model[word] #Reading word's embedding from Glove model for a given word\n","        embedding_matrix[i] = embedding_vector\n","    except:\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qeZNhU2ZEs1w"},"source":["#Word the - index 1\n","embedding_matrix[3]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wAOvV9C_KMRl"},"source":["### Build Model for Sentiment Analysis"]},{"cell_type":"code","metadata":{"id":"pWtUZzM3KMRs"},"source":["#Initialize model\n","tf.keras.backend.clear_session()\n","model = tf.keras.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DF_wJp6sKMRv"},"source":["Add Embedding layer\n"," - Embedding Layer Input = Batch_Size * Length of each review"]},{"cell_type":"code","metadata":{"id":"iignS5XqKMRv"},"source":["model.add(tf.keras.layers.Embedding(desired_vocab_size + 1, #Vocablury size\n","                                    embedding_vector_length, #Embedding size\n","                                    weights=[embedding_matrix], #Embeddings taken from pre-trained model\n","                                    trainable=False, #As embeddings are already available, we will not train this layer. It will act as lookup layer.\n","                                    input_length=max_review_length) #Number of words in each review\n","          )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9esFq2mNZfFZ"},"source":["model.output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FyKoymftKMRz"},"source":["Embedding Layer Output - \n","[Batch_Size , Review Length , Embedding_Size]"]},{"cell_type":"markdown","metadata":{"id":"d1Y5Yh8gKMR0"},"source":["Add LSTM Layer with 256 as RNN state size"]},{"cell_type":"code","metadata":{"id":"YLrE_hSGKMR2"},"source":["model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.LSTM(256)) #RNN State - size of cell state and hidden state\n","model.add(tf.keras.layers.Dropout(0.2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWABotFJac4J"},"source":["model.output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xi79uySUOS5u"},"source":["Use Dense layer for output layer"]},{"cell_type":"code","metadata":{"id":"MJ-o1jtUKMR6"},"source":["model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GobXBLHXKMR9"},"source":["#Compile the model\n","model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iueK1G3pOznW"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j_aH5TX5KMSA"},"source":["### Train Model"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"AV3TceqjKMSC"},"source":["model.fit(X_train,y_train,\n","          epochs=10,\n","          batch_size=32,          \n","          validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUWhWlaO4nHX"},"source":["model.save('Movie_with_oretrained.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ToCcMqPN4tty"},"source":["!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rtn2R1ClWJOK"},"source":["Getting output of LSTM layer"]},{"cell_type":"code","metadata":{"id":"besKpCBdVcdW"},"source":["x = model.get_layer('lstm').output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RoQfLME_VljG"},"source":["model2 = tf.keras.Model(model.input, x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnI7FHYZVpUo"},"source":["model2.predict(X_test[0:1]).shape"],"execution_count":null,"outputs":[]}]}