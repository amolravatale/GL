{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"1. Sentiment_Analysis_Embedding_RNN_LSTM.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mQKm7K78KMQa"},"source":["### Connect to Kaggle"]},{"cell_type":"markdown","metadata":{"id":"IS0axMJDKrph"},"source":["We will be using data available on Kaggle platform for this exercise. The data is available at https://www.kaggle.com/c/word2vec-nlp-tutorial/data. We will first connect Colab to Kaggle. Instructions for downloading kaggle data to Colab can be found [in this post](https://towardsdatascience.com/setting-up-kaggle-in-google-colab-ebb281b61463)."]},{"cell_type":"code","metadata":{"id":"sGWPxBNMK5XW"},"source":["!pip install kaggle --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ii1tX4nQK71e"},"source":["#Make a directory for Kaggle\n","!mkdir .kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxnI1KLhLJ_J"},"source":["#Connect Google drive to colab\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVSzOh4gLOjT"},"source":["#Copy kaggle.json file. Change gdrive folder based on where you have saved your json file from Kaggle\n","!cp '/gdrive/My Drive/AI-ML/Machine-Learning/Code/Utilities/kaggle.json' /content/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8EXjrP_LZsO"},"source":["#Check if json file is there\n","!ls -l /content/.kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DexRyePCLdFw"},"source":["!mkdir ~/.kaggle\n","!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n","!kaggle config set -n path -v{/content}\n","!chmod 600 /root/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQ2IP5KOLv3l"},"source":["Verify Kaggle connection"]},{"cell_type":"code","metadata":{"id":"e1l26nwNLvD4"},"source":["!kaggle datasets list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qaEMdD8mL0ZT"},"source":["#### Download Movie Reviews data"]},{"cell_type":"code","metadata":{"id":"repGnUbKL4DI"},"source":["!kaggle competitions download -c word2vec-nlp-tutorial -p /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFfwUE0ZMPXY"},"source":["#Confirm data has been downloaded\n","!ls -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CIxtVF3NKMQj"},"source":["Import the dataset as pandas dataframe"]},{"cell_type":"code","metadata":{"id":"GfiVR8PzKMQe"},"source":["import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5K8RSBNXKMQn"},"source":["df = pd.read_csv('labeledTrainData.tsv.zip',header=0, delimiter=\"\\t\", quoting=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P7Ds7i3TUGCr"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXwe99hqULiJ"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2U_bA5WUImd"},"source":["df.groupby(['sentiment']).count()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q12_oUDIIC-k"},"source":["df.loc[100, 'review']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"45uxRF4rKMQq"},"source":["Split Data into Training and Test Data"]},{"cell_type":"code","metadata":{"id":"cwNZ5XEpKMQq"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-RNaPq2KMQt"},"source":["train, test = train_test_split(df, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-SQC3WUyF34"},"source":["train.shape, test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTw8LKRWyOA9"},"source":["train.reset_index(inplace=True, drop=True)\n","test.reset_index(inplace=True, drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YB3iGd0OyU47"},"source":["X_train = train['review']\n","y_train = train['sentiment']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IdMWitcdByBs"},"source":["X_test = test['review']\n","y_test = test['sentiment']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"40sSeDoWKMQx"},"source":["# Build the Tokenizer"]},{"cell_type":"code","metadata":{"id":"AGM55RRUM3fN"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNB6T0EVKMQ6"},"source":["desired_vocab_size = 10000 #Vocablury size\n","t = tf.keras.preprocessing.text.Tokenizer(num_words=desired_vocab_size) # num_words -> Vocablury size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t65mfe_2KMQ8"},"source":["#Fit tokenizer with actual training data\n","t.fit_on_texts(X_train.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ht-CFBDkmwKu"},"source":["len(t.word_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6N7cgYEvVGzB"},"source":["#Vocabulary\n","print(t.word_index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2GgPOuSzKMRA"},"source":["# Prepare Training and Test Data"]},{"cell_type":"markdown","metadata":{"id":"8o8fG3FtKMRA"},"source":["Get the word index for each of the word in the review"]},{"cell_type":"code","metadata":{"id":"G9m65RFCVXCd"},"source":["X_train[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNQIpYPKKMRB"},"source":["X_train = t.texts_to_sequences(X_train.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xh1nDZFDVlB8"},"source":["print(X_train[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-eXp1Q42xyIs"},"source":["t.sequences_to_texts([X_train[0]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Gix3lNmKMRD"},"source":["X_test = t.texts_to_sequences(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hb9z28TZKMRF"},"source":["How many words in each review?"]},{"cell_type":"code","metadata":{"id":"O7maQ5kpxdfI"},"source":["len(X_train[100])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fKmVWM5pKMRF"},"source":["# Pad Sequences - Important"]},{"cell_type":"code","metadata":{"id":"h5YfEUx2KMRI"},"source":["#Define maximum number of words to consider in each review\n","max_review_length = 300"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeJeFjogKMRM"},"source":["#Pad training and test reviews\n","X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n","                                                        maxlen=max_review_length,\n","                                                        padding='pre', \n","                                                        truncating='post')\n","\n","X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, \n","                                                       maxlen=max_review_length, \n","                                                       padding='pre',\n","                                                       truncating='post')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4GLCWBOlztU"},"source":["X_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QJqX-Z5wL-W"},"source":["X_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HVteHr5IzS4I"},"source":["X_train[1000]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wAOvV9C_KMRl"},"source":["# Build the Graph"]},{"cell_type":"code","metadata":{"id":"pWtUZzM3KMRs"},"source":["#Initialize model\n","tf.keras.backend.clear_session()\n","model = tf.keras.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DF_wJp6sKMRv"},"source":["Add Embedding layer\n"," - Embedding Layer Input = Batch_Size * Length of each review"]},{"cell_type":"code","metadata":{"id":"iignS5XqKMRv"},"source":["model.add(tf.keras.layers.Embedding(desired_vocab_size + 1, #Vocablury size\n","                                    50, #Embedding size\n","                                    input_length=max_review_length) #Number of words in each review\n","          )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9esFq2mNZfFZ"},"source":["model.output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FyKoymftKMRz"},"source":["Embedding Layer Output - \n","[Batch_Size , Review Length , Embedding_Size]"]},{"cell_type":"markdown","metadata":{"id":"d1Y5Yh8gKMR0"},"source":["Add LSTM Layer with 256 as RNN state size"]},{"cell_type":"code","metadata":{"id":"YLrE_hSGKMR2"},"source":["model.add(tf.keras.layers.Dropout(0.4))\n","model.add(tf.keras.layers.LSTM(128)) #RNN State - size of cell state and hidden state"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWABotFJac4J"},"source":["model.output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HqTzLp_wvKt1"},"source":["model.add(tf.keras.layers.Dropout(0.4))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xi79uySUOS5u"},"source":["Use Dense layer for output layer"]},{"cell_type":"code","metadata":{"id":"MJ-o1jtUKMR6"},"source":["model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GobXBLHXKMR9"},"source":["#Compile the model\n","model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CFzBBFeaSoM"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j_aH5TX5KMSA"},"source":["# Execute the graph"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"AV3TceqjKMSC"},"source":["model.fit(X_train,y_train,\n","          epochs=5,\n","          batch_size=32,          \n","          validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EGunZjdmV8T2"},"source":["model.fit(X_train,y_train,\n","          initial_epoch=5,\n","          epochs=10,\n","          batch_size=32,          \n","          validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aqwf2RWBax9q"},"source":["#### Pre-Trained Embeddings"]},{"cell_type":"code","metadata":{"id":"ekTTh3HgaxGJ"},"source":["import gensim.downloader as api\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yTMnwnr4a3Uq"},"source":["#Load Glove model (similar to Word2Vec)\n","glove_model = api.load('glove-wiki-gigaword-50')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DkxOjkWga-FI"},"source":["#Size of the model\n","glove_model.vectors.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eq2emMbibWk7"},"source":["#Embedding for word great\n","glove_model['and']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-m54nDjbY4N"},"source":["#Initialize embedding matrix for our dataset with 10000+1 rows (1 for padding word)\n","#and 50 columns (as embedding size is 50)\n","embedding_matrix = np.zeros((desired_vocab_size + 1, 50))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJqcLGgsbi1Q"},"source":["for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n","    if i > (desired_vocab_size+1):\n","        break\n","    try:\n","        embedding_vector = glove_model[word] #Reading word's embedding from Glove model for a given word\n","        embedding_matrix[i] = embedding_vector\n","    except:\n","        pass"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2T2Rv2YnbwIw"},"source":["embedding_matrix[200]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U9bWA9Pab4F0"},"source":["Build a Model with Pretained Embedding"]},{"cell_type":"code","metadata":{"id":"x2UvLwY7b7sU"},"source":["#Initialize model\n","tf.keras.backend.clear_session()\n","model = tf.keras.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zjcsYC9Gb_RI"},"source":["model.add(tf.keras.layers.Embedding(desired_vocab_size + 1, #Vocablury size\n","                                    50, #Embedding size\n","                                    weights=[embedding_matrix],\n","                                    trainable=False,\n","                                    input_length=max_review_length) #Number of words in each review\n","          )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c06t9iRccQBI"},"source":["model.add(tf.keras.layers.Dropout(0.3))\n","model.add(tf.keras.layers.LSTM(128)) #RNN State - size of cell state and hidden state\n","model.add(tf.keras.layers.Dropout(0.3))\n","model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3iBPWGicjJI"},"source":["#Compile the model\n","model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swWCSO_1comQ"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tECm7Y_c6Ot"},"source":["model.fit(X_train,y_train,\n","          epochs=5,\n","          batch_size=32,          \n","          validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3nMSDzSdQEl"},"source":["model.fit(X_train,y_train,\n","          initial_epoch=5,\n","          epochs=10,\n","          batch_size=32,          \n","          validation_data=(X_test, y_test))"],"execution_count":null,"outputs":[]}]}