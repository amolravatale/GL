{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"2. Sentiment_Analysis_Pre_Trained_Embedding_RNN_LSTM.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"u2xsjLM__29H","colab_type":"text"},"source":["#### Load Data"]},{"cell_type":"code","metadata":{"id":"5ncAnX5z_5jL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CmwEJSso_wRB","colab_type":"text"},"source":["# Import Movie Review Data"]},{"cell_type":"markdown","metadata":{"id":"8hrRzs-V_wRI","colab_type":"text"},"source":["Import the dataset as pandas dataframe"]},{"cell_type":"code","metadata":{"id":"nWLUA2Mn_wRJ","colab_type":"code","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XBO4v8yv_wRL","colab_type":"text"},"source":["Data can be downloaded from Kaggle at the following URL\n","\n","- https://www.kaggle.com/c/word2vec-nlp-tutorial/data"]},{"cell_type":"code","metadata":{"id":"TV4C7TtO_wRM","colab_type":"code","colab":{}},"source":["df = pd.read_csv('labeledTrainData.tsv.zip',header=0, delimiter=\"\\t\", quoting=3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23rYVNR0_wRO","colab_type":"text"},"source":["Split Data into Training and Test Data"]},{"cell_type":"code","metadata":{"id":"qURWnAM3_wRO","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WFsMyEyN_wRQ","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    df['review'],\n","    df['sentiment'],\n","    test_size=0.2, \n","    random_state=42\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b_ms-uto_wRT","colab_type":"text"},"source":["# Build the Tokenizer"]},{"cell_type":"code","metadata":{"id":"8VRYTOBX_wRT","colab_type":"code","colab":{},"outputId":"6374454e-2bc5-4045-d8af-025f8aae9213"},"source":["from tensorflow.python.keras.preprocessing.text import Tokenizer"],"execution_count":0,"outputs":[{"output_type":"stream","text":["c:\\users\\ibm_admin\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  from ._conv import register_converters as _register_converters\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vokBmjBq_wRW","colab_type":"code","colab":{}},"source":["top_words = 10000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLol47SY_wRY","colab_type":"code","colab":{}},"source":["t = Tokenizer(num_words=top_words) # num_words -> Vocablury size"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MKUrbicS_wRa","colab_type":"code","colab":{}},"source":["t.fit_on_texts(X_train.tolist())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2CDZ-rUz_wRd","colab_type":"text"},"source":["# Prepare Training and Test Data"]},{"cell_type":"markdown","metadata":{"id":"FjCjXA3b_wRd","colab_type":"text"},"source":["Get the word index for each of the word in the review"]},{"cell_type":"code","metadata":{"id":"Zrsvq1fd_wRe","colab_type":"code","colab":{}},"source":["X_train = t.texts_to_sequences(X_train.tolist())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RW5Pi8zd_wRg","colab_type":"code","colab":{}},"source":["X_test = t.texts_to_sequences(X_test.tolist())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WTdSmaTq_wRi","colab_type":"text"},"source":["How many words in each review?"]},{"cell_type":"markdown","metadata":{"id":"7daS7zUY_wRi","colab_type":"text"},"source":["# Pad Sequences - Important"]},{"cell_type":"code","metadata":{"id":"MVdNPaGd_wRi","colab_type":"code","colab":{}},"source":["from tensorflow.python.keras.preprocessing import sequence"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtga1QUo_wRl","colab_type":"code","colab":{}},"source":["max_review_length = 300"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0BEt077q_wRn","colab_type":"code","colab":{}},"source":["X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,padding='post')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"arUFgV1R_wRp","colab_type":"code","colab":{}},"source":["X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, padding='post')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q1k75OXP_wRr","colab_type":"text"},"source":["# Build Embedding Matrix from Pre-Trained Word2Vec"]},{"cell_type":"markdown","metadata":{"id":"-dNT9EdM_wRr","colab_type":"text"},"source":["Load pre-trained Gensim Embeddings"]},{"cell_type":"code","metadata":{"id":"XAcCtFCN_wRs","colab_type":"code","colab":{},"outputId":"5dcf527f-24d2-490a-f50f-646dd8984df8"},"source":["import gensim"],"execution_count":0,"outputs":[{"output_type":"stream","text":["c:\\users\\ibm_admin\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n","  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YfTqRYGF_wRu","colab_type":"code","colab":{}},"source":["word2vec = gensim.models.Word2Vec.load('word2vec-movie-50')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P3Umrpsy_wRv","colab_type":"text"},"source":["Embedding Size"]},{"cell_type":"code","metadata":{"id":"FTyo9xTb_wRw","colab_type":"code","colab":{}},"source":["embedding_vector_length = word2vec.wv.syn0.shape[1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aYi-FQd2_wRx","colab_type":"text"},"source":["Build matrix for current data"]},{"cell_type":"code","metadata":{"id":"ZaeuwzUt_wRy","colab_type":"code","colab":{}},"source":["embedding_matrix = np.zeros((top_words + 1, embedding_vector_length))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BNJPif7r_wRz","colab_type":"code","colab":{}},"source":["for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n","    if i > top_words:\n","        break\n","    if word in word2vec.wv.vocab:\n","        embedding_vector = word2vec.wv[word]\n","        embedding_matrix[i] = embedding_vector"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6vO5OJPv_wR4","colab_type":"text"},"source":["# Build the Graph"]},{"cell_type":"code","metadata":{"id":"dmFMqp5b_wR4","colab_type":"code","colab":{}},"source":["from tensorflow.python.keras.models import Sequential"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jStLVWsQ_wR6","colab_type":"code","colab":{}},"source":["from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten, LSTM"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0GQM6-PR_wR8","colab_type":"code","colab":{}},"source":["model = Sequential()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AIQYqlS__wR-","colab_type":"text"},"source":["Add Embedding layer\n"," - Embedding Layer Input = Batch_Size * Length of each review"]},{"cell_type":"code","metadata":{"id":"O9_ZKYLp_wR-","colab_type":"code","colab":{}},"source":["model.add(Embedding(top_words + 1,\n","                    embedding_vector_length,\n","                    input_length=max_review_length,\n","                   weights=[embedding_matrix],\n","                   trainable=False)\n","         )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cCZb49uU_wSA","colab_type":"text"},"source":["Embedding Layer Output - \n","[Batch_Size , Review Length , Embedding_Size]"]},{"cell_type":"markdown","metadata":{"id":"GX8fRfPG_wSA","colab_type":"text"},"source":["Add Layer with 100 LSTM Memory Units"]},{"cell_type":"code","metadata":{"id":"CnFj1vI__wSA","colab_type":"code","colab":{}},"source":["model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n","#outout is last hidden state\n","#batch_size, 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hLFkWNBg_wSC","colab_type":"code","colab":{}},"source":["model.add(Dense(1,activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MQUrQkA_wSD","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4FTObqvf_wSF","colab_type":"text"},"source":["# Execute the graph"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"hlSY0vBV_wSF","colab_type":"code","colab":{},"outputId":"80ec8ade-b62b-4486-9767-0fb5610a784c"},"source":["model.fit(X_train,y_train,\n","          epochs=10,\n","          batch_size=128,          \n","          validation_data=(X_test, y_test),\n","         verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 20000 samples, validate on 5000 samples\n","Epoch 1/10\n","19968/20000 [============================>.] - ETA: 0s - loss: 0.6629 - acc: 0.5941"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CiPz3Tou_wSH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}