{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2. Seq2Seq LSTM Model - Translation_with_prediction_Attention.ipynb","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JoJPolOgWGG4"},"source":["### Load tensorflow"]},{"cell_type":"code","metadata":{"id":"zlt_1eHPWGG6","executionInfo":{"status":"ok","timestamp":1618122000698,"user_tz":-330,"elapsed":2664,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["import tensorflow as tf"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VzxABbMJWGG-"},"source":["### Read the data\n","<font size=\"2\">Data for this exercise can be downloaded from http://www.manythings.org/anki/</font>"]},{"cell_type":"code","metadata":{"id":"ommjMLuF75Dk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122000700,"user_tz":-330,"elapsed":2663,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"5056e37b-4a97-4825-ee86-02c10cbfd388"},"source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1vDoJM0zWGG_","executionInfo":{"status":"ok","timestamp":1618122001744,"user_tz":-330,"elapsed":3704,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#You can use wget to download the file directly\n","!wget http://www.manythings.org/anki/hin-eng.zip --quiet"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8soXgFrWGHB","executionInfo":{"status":"ok","timestamp":1618122001745,"user_tz":-330,"elapsed":3702,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["import zipfile\n","import io\n","\n","#Read the zip file\n","zf = zipfile.ZipFile('hin-eng.zip', 'r')\n","\n","#Extract data from zip file\n","data = ''\n","with zf.open('hin.txt') as readfile:\n","  for line in io.TextIOWrapper(readfile, 'utf-8'):\n","    data += line"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQFmYMvhWGHE","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1618122001745,"user_tz":-330,"elapsed":3699,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"b4d9284b-26d7-4889-930d-78ffad11fce0"},"source":["data[400:500]"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #6179123 (fastrizwaan)\\nHello!\\tनमस्'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"lx5AWe-0WGHT"},"source":["\n","### Extract Source and Target Language pairs"]},{"cell_type":"code","metadata":{"id":"mjma2IuuWGHU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122001746,"user_tz":-330,"elapsed":3698,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"593cbe5b-0e38-4f1a-e1ee-b85dec09e6ad"},"source":["#Split by newline character\n","data =  data.split('\\n')\n","\n","#Show some Data\n","data[100:105]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Bring him in.\\tउसको अंदर ले आओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #307895 (CK) & #475932 (minshirui)',\n"," 'Come with us.\\tहमारे साथ आओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433696 (CK) & #485546 (minshirui)',\n"," 'Happy Easter!\\tएसटर मुबारक हो!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #66762 (papabear) & #3189572 (pranjal710)',\n"," 'Has Tom left?\\tटॉम चला गया क्या?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2244563 (CK) & #3216282 (anubhav93)',\n"," 'I am at home.\\tमैं घर पर हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #29049 (CK) & #505256 (minshirui)']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Af9jau2XWGHX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122001747,"user_tz":-330,"elapsed":3697,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"c22f2b7e-81ec-4189-f4d8-dc56ab2f62dc"},"source":["len(data)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2916"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"A4ow84XDWGHb"},"source":["### Separate Source and Target pairs"]},{"cell_type":"code","metadata":{"id":"GTzjK4G6WGHb","executionInfo":{"status":"ok","timestamp":1618122001747,"user_tz":-330,"elapsed":3694,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["encoder_text = [] #Initialize Source language list\n","decoder_text = [] #Initialize Target language list\n","\n","#Iterate over data\n","for line in data:\n","    try:\n","        in_txt, out_txt,_ = line.split('\\t')\n","        encoder_text.append(in_txt)\n","        \n","        # Add tab '<start>' as 'start sequence in target\n","        # And '<end>' as End\n","        decoder_text.append('<start> ' + out_txt + ' <end>')\n","    except:\n","        pass #ignore data which goes into error        "],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4T4HJ3A9WGHd"},"source":["### Separate Source and Target pairs.."]},{"cell_type":"code","metadata":{"id":"xyZqwGuvWGHe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122001748,"user_tz":-330,"elapsed":3694,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"5b0a56b3-84a6-42a9-a41a-26c02c52e9f7"},"source":["encoder_text[100:105]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Bring him in.',\n"," 'Come with us.',\n"," 'Happy Easter!',\n"," 'Has Tom left?',\n"," 'I am at home.']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"v2CILOS3WGHg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122001748,"user_tz":-330,"elapsed":3692,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"df590746-4043-45d7-c82d-68786f6eec65"},"source":["decoder_text[100:105]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<start> उसको अंदर ले आओ। <end>',\n"," '<start> हमारे साथ आओ। <end>',\n"," '<start> एसटर मुबारक हो! <end>',\n"," '<start> टॉम चला गया क्या? <end>',\n"," '<start> मैं घर पर हूँ। <end>']"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"CnRP431qWGHj"},"source":["### Tokenize Source language sentences"]},{"cell_type":"code","metadata":{"id":"9ucqBYr4WGHk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122001749,"user_tz":-330,"elapsed":3185,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"209fd963-988d-4cf3-f3c6-c4c62f8685d3"},"source":["#Tokenizer for source language\n","encoder_t = tf.keras.preprocessing.text.Tokenizer()\n","encoder_t.fit_on_texts(encoder_text) #Fit it on Source sentences\n","encoder_seq = encoder_t.texts_to_sequences(encoder_text) #Convert sentences to numbers \n","encoder_seq[100:105] #Display some converted sentences"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[400, 29, 9], [49, 34, 80], [155, 1310], [42, 35, 171], [2, 67, 28, 98]]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"zZv-TPVOWGHn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122001749,"user_tz":-330,"elapsed":2685,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"0c37625e-8bdb-4d6a-b31b-95b20b9f3cd3"},"source":["#Maximum length of sentence\n","max_encoder_seq_length = max([len(txt) for txt in encoder_seq])\n","print('Maximum sentence length for Source language: ', max_encoder_seq_length)\n","\n","#Source language Vocablury\n","encoder_vocab_size = len(encoder_t.word_index)\n","print('Source language vocablury size: ', encoder_vocab_size)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Maximum sentence length for Source language:  22\n","Source language vocablury size:  2422\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BeASC50tWGHr"},"source":["### Tokenize Target language sentences"]},{"cell_type":"code","metadata":{"id":"Zcyow_keWGHr","executionInfo":{"status":"ok","timestamp":1618122002284,"user_tz":-330,"elapsed":2213,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Tokenizer for target language, filters should not <start> and <end>\n","#remove < and > used in Target language sequences\n","decoder_t = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n","decoder_t.fit_on_texts(decoder_text) #Fit it on target sentences\n","decoder_seq = decoder_t.texts_to_sequences(decoder_text) #Convert sentences to numbers "],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"phLrIK6WWGHt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122002284,"user_tz":-330,"elapsed":1345,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"4fe73feb-63b1-4909-a7d9-75ab2b64a0ba"},"source":["#Maximum length of sentence\n","max_decoder_seq_length = max([len(txt) for txt in decoder_seq])\n","print('Maximum sentence length for Target language: ', max_decoder_seq_length)\n","\n","#Target language Vocablury\n","decoder_vocab_size = len(decoder_t.word_index)\n","print('Target language vocablury size: ', decoder_vocab_size)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Maximum sentence length for Target language:  27\n","Target language vocablury size:  3047\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6fXf48uMWGH6"},"source":["### Compare different sentences length"]},{"cell_type":"code","metadata":{"id":"w0aRkCfiWGH7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122003134,"user_tz":-330,"elapsed":802,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"ba4433f9-ad26-4633-d41c-619ef7b2e38e"},"source":["#Source Language sentences\n","print('Length for sentence number 100: ', len(encoder_seq[100]))\n","print('Length for sentence number 2000: ', len(encoder_seq[2000]))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Length for sentence number 100:  3\n","Length for sentence number 2000:  7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W2qZN4BvWGH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122006884,"user_tz":-330,"elapsed":1154,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"848de0e8-baab-4b3a-e5df-44fc556e0c37"},"source":["#Target Language sentences\n","print('Length for sentence number 100: ', len(decoder_seq[100]))\n","print('Length for sentence number 2000: ', len(decoder_seq[2000]))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Length for sentence number 100:  6\n","Length for sentence number 2000:  8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wmeSCSs6WGIC"},"source":["### How do we make it same?"]},{"cell_type":"markdown","metadata":{"id":"mqps8juMWGIE"},"source":["### Padding the sentences"]},{"cell_type":"code","metadata":{"id":"8rnbyRs9WGIF","executionInfo":{"status":"ok","timestamp":1618122008638,"user_tz":-330,"elapsed":1156,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Source sentences\n","encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq, \n","                                                                   maxlen=max_encoder_seq_length, #22\n","                                                                   padding='pre')\n","\n","#Target Sentences\n","decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(decoder_seq, \n","                                                                   maxlen=max_decoder_seq_length, #27\n","                                                                   padding='post')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"a61g_ADpWGIH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122009228,"user_tz":-330,"elapsed":1277,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"72b1649c-e889-47bb-b654-f26522c3b6e2"},"source":["print('Source data shape: ', encoder_input_data.shape)\n","print('Target data shape: ', decoder_input_data.shape)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Source data shape:  (2915, 22)\n","Target data shape:  (2915, 27)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Nl4oxg8cWGIJ"},"source":["#### Integer to Word converter for Decoder data"]},{"cell_type":"code","metadata":{"id":"jhwnBD-0WGIK","executionInfo":{"status":"ok","timestamp":1618122010160,"user_tz":-330,"elapsed":1005,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8TP07uxWGIP","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1618122010525,"user_tz":-330,"elapsed":941,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"7f0aa18d-344c-4808-bc82-bfbabc547b2f"},"source":["int_to_word_decoder[15]"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'हैं।'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"5g4Y4oRvWGIV"},"source":["### Building Decoder Output"]},{"cell_type":"code","metadata":{"id":"YuoPA9aWWGIV","executionInfo":{"status":"ok","timestamp":1618122012923,"user_tz":-330,"elapsed":970,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["import numpy as np\n","\n","#Initialize array\n","decoder_target_data = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1]))\n","\n","#Shift Target output by one word\n","for i in range(decoder_input_data.shape[0]):\n","    for j in range(1,decoder_input_data.shape[1]):\n","        decoder_target_data[i][j-1] = decoder_input_data[i][j]"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"haordQCuWGIX"},"source":["#### Convert target data in one hot vector"]},{"cell_type":"code","metadata":{"id":"Vs2SKKI5WGIY","executionInfo":{"status":"ok","timestamp":1618122014634,"user_tz":-330,"elapsed":1773,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Initialize one hot encoding array\n","decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], #number of sentences\n","                                   decoder_input_data.shape[1], #Number of words in each sentence\n","                                   len(decoder_t.word_index)+1)) #Vocab size + 1"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"xoX_6OP4WGIm","executionInfo":{"status":"ok","timestamp":1618122016915,"user_tz":-330,"elapsed":1705,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Build one hot encoded array\n","for i in range(decoder_target_data.shape[0]):\n","    for j in range(decoder_target_data.shape[1]):\n","        decoder_target_one_hot[i][j] = tf.keras.utils.to_categorical(decoder_target_data[i][j],\n","                                                                     num_classes=len(decoder_t.word_index)+1)    "],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y5fO1TTWWGIo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122017366,"user_tz":-330,"elapsed":1052,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"cf00dff2-52b2-4c00-f9f7-7e5daa6878fa"},"source":["decoder_target_one_hot.shape"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2915, 27, 3048)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"fQYFym0AWGIq"},"source":["### Building the Training Model"]},{"cell_type":"code","metadata":{"id":"XnDjHynRi24U","executionInfo":{"status":"ok","timestamp":1618122018601,"user_tz":-330,"elapsed":622,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["tf.keras.backend.clear_session()"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"fRfYeB2AWGIr","executionInfo":{"status":"ok","timestamp":1618122023712,"user_tz":-330,"elapsed":983,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Define config parameters\n","encoder_embedding_size = 50\n","decoder_embedding_size = 50\n","rnn_units = 256"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"71ukvjyeWGIt"},"source":["#### Build Encoder"]},{"cell_type":"code","metadata":{"id":"2SHW_YvkWGIw","executionInfo":{"status":"ok","timestamp":1618122063426,"user_tz":-330,"elapsed":1054,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Input Layer\n","encoder_inputs = tf.keras.layers.Input(shape=(22,))\n","\n","#Embedding layer\n","encoder_embedding = tf.keras.layers.Embedding(encoder_vocab_size+1, encoder_embedding_size)\n","\n","#Get embedding layer output by feeding inputs\n","encoder_embedding_output = encoder_embedding(encoder_inputs)\n","\n","#---Following code has been commented out for Attention-------\n","#LSTM Layer and its output\n","#x, state_h, state_c = tf.keras.layers.LSTM(rnn_units,return_state=True)(encoder_embedding_output)\n","\n","#Build a list to feed Decoder\n","#encoder_states = [state_h, state_c]"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YbfLAFglWGIx"},"source":["#### Build Encoder - Get all hidden states"]},{"cell_type":"code","metadata":{"id":"EnZJnNSbWGIz","executionInfo":{"status":"ok","timestamp":1618122082104,"user_tz":-330,"elapsed":1521,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Create LSTM Layer and get All hidden states, last hidden and cell state\n","encoder_lstm = tf.keras.layers.LSTM(rnn_units,return_state=True, return_sequences=True)\n","\n","#Get 3 outputs of LSTM Layer\n","encoder_all_h_states, state_h, state_c = encoder_lstm(encoder_embedding_output)\n","\n","#Build a list to feed Decoder\n","encoder_states = [state_h, state_c]"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OcK7SYUjDdf","executionInfo":{"status":"ok","timestamp":1618122084975,"user_tz":-330,"elapsed":976,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"4b4ee694-783e-4ba8-abd0-bf045f7768d0"},"source":["encoder_all_h_states"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 22, 256) dtype=float32 (created by layer 'lstm')>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"RAIuXWK5WGI1"},"source":["#### Build Decoder"]},{"cell_type":"code","metadata":{"id":"uYY-zwUSWGI2","executionInfo":{"status":"ok","timestamp":1618122156040,"user_tz":-330,"elapsed":976,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Decode input - padded Target sentences\n","decoder_inputs = tf.keras.layers.Input(shape=(27,))\n","\n","#Decoder Embedding layer\n","decoder_embedding = tf.keras.layers.Embedding(decoder_vocab_size + 1, decoder_embedding_size)\n","\n","#Embedding layer output\n","decoder_embedding_output = decoder_embedding(decoder_inputs)\n","\n","#Decoder RNN\n","decoder_rnn = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n","\n","#Decoder RNN Output, State initialization from Encoder states\n","#Output will be all hidden sequences, last 'h' state and last 'c' state\n","decoder_all_h_states,_,_ = decoder_rnn(decoder_embedding_output, \n","                                       initial_state=encoder_states)\n","\n","#---Following code has been commented out for Attention-------\n","#Output Layer\n","#decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n","\n","#Output of Dense layer\n","#decoder_outputs = decoder_dense(x)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLmAljrtjAGq","executionInfo":{"status":"ok","timestamp":1618122157724,"user_tz":-330,"elapsed":1286,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"270c98fa-21e8-4096-f3cd-853ff5602352"},"source":["decoder_all_h_states"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 27, 256) dtype=float32 (created by layer 'lstm_1')>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"QwtwXesXWGI4"},"source":["#### Build Decoder...Alignment Matrix"]},{"cell_type":"code","metadata":{"id":"mOJtf8kMWGI5","executionInfo":{"status":"ok","timestamp":1618122200319,"user_tz":-330,"elapsed":962,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#1. Dot Product between Decoder_all_h_states and encoder_all_h_states\n","#2. Apply softmax to get Alignment matrix\n","\n","#Dimensions details\n","#decoder_all_states = batch_size x max_decoder_length x rnn_units\n","#encoder_all_states = batch_size x max_encoder_length x rnn_units\n","#score = batch_size x max_decoder_length x max_encoder_length\n","#alignment matrix = batch_size x max_decoder_length x max_encoder_length\n","\n","score = tf.keras.layers.dot([decoder_all_h_states, encoder_all_h_states], axes=2)\n","alignment_matrix = tf.keras.layers.Activation('softmax')(score)\n","\n","#Try general and concat approaches to alignment matrix"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"SNzzFkm4W0N8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122203227,"user_tz":-330,"elapsed":888,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"d9c2d323-fa5c-4b04-cd6d-326d3c627de1"},"source":["alignment_matrix"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 27, 22) dtype=float32 (created by layer 'activation')>"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"cYFfIGyvWGI6"},"source":["#### Build Decoder...Context Vector"]},{"cell_type":"code","metadata":{"id":"h4ICneq6WGI6","executionInfo":{"status":"ok","timestamp":1618122244615,"user_tz":-330,"elapsed":920,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Weighted sum of multiplication of Alignment matrix and encoder states\n","#Dimension of context_vector =  batch_size x max_decoder_length x rnn_units\n","\n","context_vector = tf.keras.layers.dot([alignment_matrix, encoder_all_h_states], axes=[2,1])"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3EtN7Ho9fHy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122246284,"user_tz":-330,"elapsed":979,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"5e217b0d-0825-4d1c-e0d7-4290613e0183"},"source":["context_vector"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 27, 256) dtype=float32 (created by layer 'dot_1')>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"4GOKQuJiWGI8"},"source":["#### Build Decoder...Attention Vector"]},{"cell_type":"code","metadata":{"id":"L9aJaK5LWGI8","executionInfo":{"status":"ok","timestamp":1618122283904,"user_tz":-330,"elapsed":941,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Concatenate context vector and decoder_all_h_states\n","#context_decoder_hidden = batch_size x max_decoder_length x rnn_units\n","#attention_vector = batch_size x max_decoder_length x 128\n","\n","context_decoder_hidden = tf.keras.layers.concatenate([context_vector, \n","                                                      decoder_all_h_states])\n","\n","attention_dense_layer = tf.keras.layers.Dense(128, use_bias=False, \n","                                              activation='relu')\n","\n","attention_vector = attention_dense_layer(context_decoder_hidden)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"v1nE-nHNfqix","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122285581,"user_tz":-330,"elapsed":1285,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"b56dc56a-311f-4522-d7a7-ae5b51a45c72"},"source":["attention_vector"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 27, 128) dtype=float32 (created by layer 'dense')>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"yvcsEikBWGI-"},"source":["#### Build Decoder...Output layer"]},{"cell_type":"code","metadata":{"id":"GinU4PH5WGI_","executionInfo":{"status":"ok","timestamp":1618122391069,"user_tz":-330,"elapsed":2961,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["#Output layer\n","decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n","\n","#With attention input will be attention_vector and not decoder_all_h_states\n","decoder_outputs = decoder_dense(attention_vector)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K2CHFVvmkB06","executionInfo":{"status":"ok","timestamp":1618122394068,"user_tz":-330,"elapsed":2190,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"fb2bbfcd-a1b1-40e4-c8f2-bbfd3ce1b5e4"},"source":["decoder_outputs"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 27, 3048) dtype=float32 (created by layer 'dense_1')>"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"__FmqX3qWGJL"},"source":["### Build Model using both Encoder and Decoder"]},{"cell_type":"code","metadata":{"id":"IbtWE0_JWGJL","executionInfo":{"status":"ok","timestamp":1618122399786,"user_tz":-330,"elapsed":1867,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["model = tf.keras.models.Model([encoder_inputs, decoder_inputs], #2 Inputs to the model\n","                              decoder_outputs) #Output of the model"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"WG4pyK_jWGJO","executionInfo":{"status":"ok","timestamp":1618122399787,"user_tz":-330,"elapsed":1865,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}}},"source":["model.compile(optimizer='adam', \n","              loss='categorical_crossentropy', \n","              metrics=['accuracy'])"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"xA0TU2tCVYLO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122399787,"user_tz":-330,"elapsed":1755,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"0be8bfdb-a8a8-4004-a851-b2bd1b2a7d0a"},"source":["model.summary()"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 22)]         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 27)]         0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 22, 50)       121150      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 27, 50)       152400      input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 22, 256), (N 314368      embedding[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 27, 256), (N 314368      embedding_1[0][0]                \n","                                                                 lstm[0][1]                       \n","                                                                 lstm[0][2]                       \n","__________________________________________________________________________________________________\n","dot (Dot)                       (None, 27, 22)       0           lstm_1[0][0]                     \n","                                                                 lstm[0][0]                       \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 27, 22)       0           dot[0][0]                        \n","__________________________________________________________________________________________________\n","dot_1 (Dot)                     (None, 27, 256)      0           activation[0][0]                 \n","                                                                 lstm[0][0]                       \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 27, 512)      0           dot_1[0][0]                      \n","                                                                 lstm_1[0][0]                     \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 27, 128)      65536       concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 27, 3048)     393192      dense[0][0]                      \n","==================================================================================================\n","Total params: 1,361,014\n","Trainable params: 1,361,014\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uHhrDTBZWGJQ"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"81ciKSvCWGJQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618122767637,"user_tz":-330,"elapsed":366957,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"873cc638-e65c-4d73-c8c0-05ed7300d4b1"},"source":["model.fit([encoder_input_data, decoder_input_data], decoder_target_one_hot,\n","          batch_size=64,\n","          epochs=25,\n","          validation_split=0.2)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","37/37 [==============================] - 19s 420ms/step - loss: 5.5297 - accuracy: 0.6568 - val_loss: 3.0604 - val_accuracy: 0.5928\n","Epoch 2/25\n","37/37 [==============================] - 14s 391ms/step - loss: 1.6720 - accuracy: 0.7411 - val_loss: 3.1239 - val_accuracy: 0.5958\n","Epoch 3/25\n","37/37 [==============================] - 14s 391ms/step - loss: 1.5774 - accuracy: 0.7467 - val_loss: 3.0422 - val_accuracy: 0.5959\n","Epoch 4/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.5132 - accuracy: 0.7510 - val_loss: 2.8482 - val_accuracy: 0.6055\n","Epoch 5/25\n","37/37 [==============================] - 14s 388ms/step - loss: 1.4183 - accuracy: 0.7704 - val_loss: 2.8108 - val_accuracy: 0.6228\n","Epoch 6/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.3822 - accuracy: 0.7789 - val_loss: 2.7486 - val_accuracy: 0.6333\n","Epoch 7/25\n","37/37 [==============================] - 14s 393ms/step - loss: 1.3481 - accuracy: 0.7820 - val_loss: 2.8157 - val_accuracy: 0.6330\n","Epoch 8/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.3194 - accuracy: 0.7851 - val_loss: 2.7897 - val_accuracy: 0.6335\n","Epoch 9/25\n","37/37 [==============================] - 14s 389ms/step - loss: 1.3200 - accuracy: 0.7826 - val_loss: 2.7949 - val_accuracy: 0.6371\n","Epoch 10/25\n","37/37 [==============================] - 14s 391ms/step - loss: 1.2989 - accuracy: 0.7851 - val_loss: 2.8075 - val_accuracy: 0.6360\n","Epoch 11/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.2778 - accuracy: 0.7879 - val_loss: 2.8182 - val_accuracy: 0.6372\n","Epoch 12/25\n","37/37 [==============================] - 14s 391ms/step - loss: 1.2515 - accuracy: 0.7911 - val_loss: 2.8081 - val_accuracy: 0.6403\n","Epoch 13/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.2474 - accuracy: 0.7921 - val_loss: 2.8458 - val_accuracy: 0.6393\n","Epoch 14/25\n","37/37 [==============================] - 14s 391ms/step - loss: 1.2324 - accuracy: 0.7922 - val_loss: 2.8451 - val_accuracy: 0.6406\n","Epoch 15/25\n","37/37 [==============================] - 14s 388ms/step - loss: 1.2327 - accuracy: 0.7922 - val_loss: 2.9408 - val_accuracy: 0.6400\n","Epoch 16/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.2089 - accuracy: 0.7940 - val_loss: 2.8880 - val_accuracy: 0.6421\n","Epoch 17/25\n","37/37 [==============================] - 14s 388ms/step - loss: 1.2049 - accuracy: 0.7935 - val_loss: 2.9712 - val_accuracy: 0.6416\n","Epoch 18/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.1835 - accuracy: 0.7950 - val_loss: 2.9622 - val_accuracy: 0.6408\n","Epoch 19/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.1810 - accuracy: 0.7951 - val_loss: 3.0134 - val_accuracy: 0.6429\n","Epoch 20/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.1501 - accuracy: 0.7978 - val_loss: 2.9544 - val_accuracy: 0.6459\n","Epoch 21/25\n","37/37 [==============================] - 14s 390ms/step - loss: 1.1616 - accuracy: 0.7965 - val_loss: 3.0481 - val_accuracy: 0.6434\n","Epoch 22/25\n","37/37 [==============================] - 14s 391ms/step - loss: 1.1353 - accuracy: 0.7989 - val_loss: 3.0163 - val_accuracy: 0.6477\n","Epoch 23/25\n","37/37 [==============================] - 14s 388ms/step - loss: 1.1292 - accuracy: 0.7996 - val_loss: 3.0710 - val_accuracy: 0.6455\n","Epoch 24/25\n","37/37 [==============================] - 14s 387ms/step - loss: 1.1085 - accuracy: 0.8000 - val_loss: 3.0656 - val_accuracy: 0.6467\n","Epoch 25/25\n","37/37 [==============================] - 14s 388ms/step - loss: 1.0926 - accuracy: 0.8031 - val_loss: 3.0574 - val_accuracy: 0.6476\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f6442a58890>"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"0gO-p-OaWGJT"},"source":["### Save the model for later reuse"]},{"cell_type":"code","metadata":{"id":"GUJcwtNyWGJU"},"source":["#model.save('models/seq2seq_training_translation_attention.hd5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjuM6UkoWGJW"},"source":["model = tf.keras.models.load_model('models/seq2seq_training_translation_attention.hd5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z8k64d1HWGJY"},"source":["# Building Model for Prediction"]},{"cell_type":"markdown","metadata":{"id":"_w__FLXCWGJZ"},"source":["### Build the Encoder Model to predict Encoder States"]},{"cell_type":"code","metadata":{"id":"x9sSoCtMWGJZ"},"source":["encoder_model = tf.keras.models.Model(inputs=encoder_inputs, #Padded input sequences\n","                                      outputs=[encoder_all_h_states] + #Hidden states at all time steps\n","                                      encoder_states) #Hidden state and Cell state at last time step"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RScHHgr5WGJb"},"source":["### Build the Decoder Model \n","<p/>\n","\n","<ol><li>Define Input for both 'h' state and 'c' state initialization </li>\n","    <li><font color=\"blue\">Define Input for all encoder states - Attention Layer </font></li>\n","<li>Get Decoder RNN outputs along with h and c state</li>\n","<li><font color=\"blue\">Build Attention Layer</font></li>\n","<li><font color=\"blue\">Get Decoder Dense layer output using Attention vector</font></li>\n","    <li><font color=\"blue\">Build Model</font></li></ol>"]},{"cell_type":"markdown","metadata":{"id":"fZGRM_UQWGJc"},"source":["##### Step 1 - Define Input for both 'h' state and 'c' state initialization"]},{"cell_type":"code","metadata":{"id":"Wq4XvgTAWGJc"},"source":["#Hidden state input\n","decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_units,))\n","\n","#Cell state input\n","decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_units,))\n","\n","#Putting it together\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U4rg9wJMWGJe"},"source":["##### Step 2 - Define Input encoder states - Attention Layer"]},{"cell_type":"code","metadata":{"id":"SYozwBH2WGJe"},"source":["encoder_outputs = tf.keras.layers.Input(shape=(max_encoder_seq_length, rnn_units,))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cu7AJ7teWGJg"},"source":["##### Step 3 - Get Decoder RNN outputs along with h and c state"]},{"cell_type":"code","metadata":{"id":"TPbxVkdoWGJh"},"source":["#Get Embedding layer output\n","x = decoder_embedding(decoder_inputs)\n","\n","#We will use the layer which we trained earlier\n","rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)\n","\n","#Why do we need this?\n","decoder_states = [state_h, state_c]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YnDK-mtkWGJk"},"source":["##### Step 4 - Build Attention Layer"]},{"cell_type":"code","metadata":{"id":"9RFkceyHWGJk"},"source":["#Alignment score\n","p_score = tf.keras.layers.dot([rnn_outputs, encoder_outputs], axes=2)\n","\n","#Perform softmax to get Alignment matrix\n","p_alignment_matrix = tf.keras.layers.Activation('softmax')(p_score)\n","\n","#Context Vector\n","p_context_vector = tf.keras.layers.dot([p_alignment_matrix, encoder_outputs], axes=[2,1])\n","\n","#Build Attention Vector\n","# 1. Caoncatenate both context vector and decoder outputs\n","# 2. Feed it to the Dense layer \n","p_context_decoder_hidden = tf.keras.layers.concatenate([p_context_vector, rnn_outputs])\n","p_attention_vector = attention_dense_layer(p_context_decoder_hidden)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CLw9G3KkWGJl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614515704760,"user_tz":-330,"elapsed":962,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"2d0112a9-d3a8-4e0c-894a-80a18d0d8773"},"source":["p_alignment_matrix"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, 27, 22) dtype=float32 (created by layer 'activation_1')>"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"fUVTE025WGJn"},"source":["##### Step 5 - Get Decoder Dense layer output"]},{"cell_type":"code","metadata":{"id":"o60fmWbJWGJo"},"source":["decoder_outputs = decoder_dense(p_attention_vector)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oE7o-lOfWGJ3"},"source":["##### Step 6 - Build Decoder Model"]},{"cell_type":"code","metadata":{"id":"545vI4cXWGJ4"},"source":["#3 Inputs - Word, h/c state and all hidden states from encoder\n","#3 Outputs - predicted word, h and c state values for next run and alignment matrix for visualization\n","\n","decoder_model = tf.keras.models.Model([decoder_inputs] +  #Start sequence and then word\n","                                      decoder_states_inputs + #h and c state value for initialization\n","                                      [encoder_outputs],  #Encoder all hidden states for Attention layer\n","                                      [decoder_outputs] + #Model word prediction\n","                                      decoder_states +   #h and c states for next run\n","                                      [p_alignment_matrix]) #for Alignment matrix"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G7VEzNGyWGJ5"},"source":["# Predicting output from Seq2Seq model"]},{"cell_type":"markdown","metadata":{"id":"mcg5mBcYWGJ6"},"source":["##### Build a prediction function"]},{"cell_type":"code","metadata":{"id":"J1VoPsIkWGJ6"},"source":["def decode_sentence(input_sequence):\n","    \n","    #Get the encoder state values\n","    encoder_output =  encoder_model.predict(input_sequence)\n","    decoder_initial_states_value = encoder_output[1:]    \n","    encoded_seqs = encoder_output[0]\n","    \n","    #Build a sequence with '<start>' - starting sequence for Decoder\n","    target_seq = np.zeros((1,1))    \n","    target_seq[0][0] = decoder_t.word_index['<start>']\n","    \n","    #flag to check if prediction should be stopped\n","    stop_loop = False\n","    \n","    #Initialize predicted sentence\n","    predicted_sentence = ''\n","    \n","    #start the loop\n","    while not stop_loop:\n","        \n","        #Decoder model with 3 inputs\n","        predicted_outputs, h, c, a_matrix = decoder_model.predict([target_seq] + \n","                                                                  decoder_initial_states_value +\n","                                                                  [encoded_seqs])\n","        \n","        #Get the predicted word index with highest probability\n","        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n","        \n","        #Get the predicted word from predicter index\n","        if (predicted_output == 0):\n","            predicted_word = ' '\n","        else:\n","            predicted_word = int_to_word_decoder[predicted_output]\n","        \n","        #Check if prediction should stop\n","        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n","            \n","            stop_loop = True\n","            continue\n","                    \n","        #Updated predicted sentence\n","        if (len(predicted_sentence) == 0):\n","            predicted_sentence = predicted_word\n","        else:\n","            predicted_sentence = predicted_sentence + ' ' + predicted_word\n","            \n","        #Update target_seq to be the predicted word index\n","        target_seq[0][0] = predicted_output\n","        \n","        #Update initial states value for decoder\n","        decoder_initial_states_value = [h,c]\n","        \n","        print(a_matrix[0][0])\n","    \n","    return predicted_sentence"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CuQcVTVZWGJ8"},"source":["##### Call Prediction function on a random sentence"]},{"cell_type":"code","metadata":{"id":"jkJznTF8WGJ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614515823486,"user_tz":-330,"elapsed":1111,"user":{"displayName":"Rajeev Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioCHieeX70716XQKZdkNyhzUzFoLM7f-bMbST-wQM=s64","userId":"10567937244174773728"}},"outputId":"ad33e0a1-03f4-42be-bb1a-9bb62e009ff6"},"source":["#Generate a random number\n","start_num = np.random.randint(0, high=len(encoder_text) - 10)\n","\n","#Predict model output for 5 sentences\n","for i in range(start_num, start_num + 1):\n","    input_seq = encoder_input_data[i : i+1]\n","    #print(input_seq)\n","    predicted_sentence = decode_sentence(input_seq)\n","    print('--------')\n","    print ('Input sentence: ', encoder_text[i])\n","    print ('Predicted sentence: ', predicted_sentence )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7257522e-38\n"," 2.2333274e-28 2.8964719e-23 5.8233591e-22 7.9554605e-22 7.4699857e-22\n"," 7.1089560e-22 6.9270803e-22 6.8192176e-22 6.7467676e-22 6.6960518e-22\n"," 6.6597258e-22 6.6334574e-22 3.5199642e-01 5.7034897e-17 1.4445786e-17\n"," 6.4800358e-01 1.4156054e-18]\n","[1.5960951e-28 1.2753956e-27 4.8009357e-26 2.8767649e-23 5.8000302e-19\n"," 9.8376041e-15 9.1687194e-13 2.2439971e-12 2.1698270e-12 1.9695775e-12\n"," 1.8592181e-12 1.7977728e-12 1.7592386e-12 1.7332331e-12 1.7150411e-12\n"," 1.7020062e-12 1.6925209e-12 5.7460177e-01 9.7773886e-11 1.2535034e-10\n"," 4.2539823e-01 1.5655536e-11]\n","[4.8648759e-27 3.2611947e-26 9.2650846e-25 3.5856389e-22 4.3836999e-18\n"," 6.5109844e-14 7.9814809e-12 2.4909907e-11 2.6364862e-11 2.4354879e-11\n"," 2.2978829e-11 2.2164713e-11 2.1651351e-11 2.1308524e-11 2.1071362e-11\n"," 2.0903475e-11 2.0782143e-11 5.5874556e-01 1.0361688e-09 1.1667703e-09\n"," 4.4125444e-01 2.4032337e-10]\n","[1.3910695e-26 9.5472649e-26 2.8698282e-24 1.3503641e-21 3.5127270e-17\n"," 3.6682788e-12 4.0431254e-09 4.1639183e-08 6.6299023e-08 6.8230278e-08\n"," 6.6166379e-08 6.4365452e-08 6.3092102e-08 6.2199312e-08 6.1566190e-08\n"," 6.1111315e-08 6.0780714e-08 4.7892576e-01 5.3884742e-06 4.0581349e-06\n"," 5.2106029e-01 3.8898434e-06]\n","--------\n","Input sentence:  I wasn't fired. I quit.\n","Predicted sentence:  मुझे बहुत नहीं है।\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YS-RjZPlWGJ-"},"source":["##### Save encoder and decoder model"]},{"cell_type":"code","metadata":{"id":"2l-qAT-bWGJ-"},"source":["#Compile models to avoid error\n","encoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n","decoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n","\n","#Save the models\n","encoder_model.save('models/seq2seq_encoder_eng_hin.hd5')  #Encoder model\n","decoder_model.save('models/seq2seq_decoder_eng_hin.hd5')  #Decoder model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oh0okCv0WGKA"},"source":["##### Save encoder and decoder tokenizers"]},{"cell_type":"code","metadata":{"id":"Qwfb-v7OWGKB"},"source":["import pickle\n","\n","pickle.dump(encoder_t,open('models/encoder_tokenizer_eng','wb'))\n","pickle.dump(decoder_t,open('models/decoder_tokenizer_hin','wb'))"],"execution_count":null,"outputs":[]}]}