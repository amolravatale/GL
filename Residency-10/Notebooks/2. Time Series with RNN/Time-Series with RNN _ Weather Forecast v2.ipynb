{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8ewHTEJUO-0"
   },
   "source": [
    "#### Download data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPLC4rjgUYcu"
   },
   "source": [
    "We will use [weather data](https://www.bgc-jena.mpg.de/wetter/) provided by [Max Plank Institute for BiogeoChemistry](https://www.bgc-jena.mpg.de)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gJFl3t7T9mH"
   },
   "outputs": [],
   "source": [
    "#Download the data\n",
    "!wget https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QA1E1n_dU-s2"
   },
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dYjJ0fjVCaa"
   },
   "outputs": [],
   "source": [
    "#Unzip the file\n",
    "!unzip jena_climate_2009_2016.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tn0OHK5fVHUM"
   },
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwKs9c39VLNJ"
   },
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVJNv5ZBVJB6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjOhCyNyVfTx"
   },
   "outputs": [],
   "source": [
    "#Read dataset\n",
    "df = pd.read_csv('jena_climate_2009_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vby_QvApVr_9"
   },
   "outputs": [],
   "source": [
    "#Let's check the dataset contents\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EyHeCXsmV50u"
   },
   "outputs": [],
   "source": [
    "#Columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mNp7FPGygW3"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmxiZdWhVxJP"
   },
   "outputs": [],
   "source": [
    "#Check number of records\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pj8PLml0XIbq"
   },
   "source": [
    "What is the Frequency of this Time-Series data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fR-KNtgIXMEZ"
   },
   "outputs": [],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oN5gSrB5Znty"
   },
   "outputs": [],
   "source": [
    "#Check if null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqf4o4tNZ1-E"
   },
   "source": [
    "How should we deal missing values in Time Series data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJi2VdvRYowB"
   },
   "source": [
    "#### Data for Air Tempreture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mn2-tk99Yrcy"
   },
   "source": [
    "Excercise #1 : Build a model which will predict future 'Air Tempreture' based on the past data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAmR0OUjY3xb"
   },
   "outputs": [],
   "source": [
    "#Get data for Air Tempreture\n",
    "temp_df = df['T (degC)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuwqimSdY_5X"
   },
   "outputs": [],
   "source": [
    "#Make Date time column as index to make sure data is sorted\n",
    "temp_df.index = df['Date Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLAKBS8tZI37"
   },
   "outputs": [],
   "source": [
    "#Check data\n",
    "temp_df.head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Q1hqMTk3X-f"
   },
   "outputs": [],
   "source": [
    "temp_df.tail(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qL7jDrLZd6n"
   },
   "outputs": [],
   "source": [
    "#Visualize data\n",
    "temp_df.plot(subplots=True, figsize=(10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpJ-_eeI0PTg"
   },
   "outputs": [],
   "source": [
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvm_3cypaexT"
   },
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7fmyLEWaklE"
   },
   "source": [
    "Split data between Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1aZc988aiWM"
   },
   "outputs": [],
   "source": [
    "#Number of training examples - set to 80%\n",
    "num_training_examples = int(0.8 * temp_df.shape[0])\n",
    "num_training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eD-WyRfmb_Kk"
   },
   "outputs": [],
   "source": [
    "#Prepare training and test data\n",
    "train_data = temp_df.to_list()[:num_training_examples]\n",
    "test_data = temp_df.to_list()[num_training_examples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2EA4Nvtdcvui"
   },
   "outputs": [],
   "source": [
    "#Check the data\n",
    "print(train_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5piS8roK48md"
   },
   "outputs": [],
   "source": [
    "#Find the mean standard deviation\n",
    "mean = np.array(train_data).mean()\n",
    "std = np.array(train_data).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yi07q2f6YI-Z"
   },
   "outputs": [],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L91mvnS0ds_5"
   },
   "source": [
    "Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0_n02Hcfb1X"
   },
   "outputs": [],
   "source": [
    "#Normalize training and test data\n",
    "norm_train = (np.array(train_data) - mean)/std\n",
    "norm_test  = (np.array(test_data) - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THzDm6xq5LH9"
   },
   "outputs": [],
   "source": [
    "norm_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qf07_O2Vf-W2"
   },
   "outputs": [],
   "source": [
    "def prepare_xy(dataset, window_size=20):\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "    \n",
    "    for i in range(len(dataset)-window_size):\n",
    "        \n",
    "        #Prepare input features\n",
    "        input_features = dataset[i:(i+window_size)]        \n",
    "        dataX.append(input_features)\n",
    "\n",
    "        #Prepare Label\n",
    "        label = dataset[i + window_size]\n",
    "        dataY.append(label)\n",
    "    \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BosoDXyf2WQ"
   },
   "outputs": [],
   "source": [
    "#Prepare x,y for train and test\n",
    "train_x, train_y = prepare_xy(norm_train)\n",
    "test_x, test_y = prepare_xy(norm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7AvEtT5f30e"
   },
   "source": [
    "Build X (Input features) and y (Label) for Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQspsvJvhjXt"
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XtReVUlopn6"
   },
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTzDIY_Shl-j"
   },
   "outputs": [],
   "source": [
    "#First example input features (x)\n",
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkbT1ZQXhwYT"
   },
   "outputs": [],
   "source": [
    "#First example label (y)\n",
    "train_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNO-la5TjMau"
   },
   "source": [
    "Visualize single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZaP0m6qQjPEA"
   },
   "outputs": [],
   "source": [
    "def show_example(input_features, target, prediction=None):\n",
    "\n",
    "    #Plot historical values\n",
    "    plt.plot(list(range(input_features.shape[0])), input_features.flatten(), '.-', label='History' )\n",
    "    \n",
    "    #Plot target\n",
    "    plt.plot(input_features.shape[0]+1, target, 'rx', markersize=10, label='Actual')\n",
    "\n",
    "    #Plot prediction, if applicable\n",
    "    if prediction:\n",
    "        plt.plot(input_features.shape[0]+1, prediction, 'go', markersize=10, label='Prediction')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEWFwbnlmGTu"
   },
   "outputs": [],
   "source": [
    "#Display examples\n",
    "exp_num = np.random.randint(0, train_x.shape[0])\n",
    "show_example(train_x[exp_num], train_y[exp_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2knlmVnpnw7o"
   },
   "source": [
    "Prediction using Average method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgTOSWW5nzy2"
   },
   "outputs": [],
   "source": [
    "#Prediction is taken as average of all the points in sequence e.g 20\n",
    "exp_num = np.random.randint(0, train_x.shape[0])\n",
    "show_example(train_x[exp_num], train_y[exp_num], train_x[exp_num].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOrQuVVNoZVs"
   },
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXCHSg0oobNB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyVKIYeuouHj"
   },
   "outputs": [],
   "source": [
    "#Random seed for reproducibility\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUOWIGahocrE"
   },
   "outputs": [],
   "source": [
    "#Build Model\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "#Add LSTM layer\n",
    "model.add(tf.keras.layers.LSTM(8, input_shape=(train_x.shape[1], 1,)))\n",
    "\n",
    "#Add Output layer\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WaACfASr3HX"
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rK1L2d6Mq3Dn"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M09Jxr3-sMW_"
   },
   "source": [
    "Train the model\n",
    "\n",
    "- Convert batch to be 3 dimensional data : Batch size x Sequence length x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DO2PxuC_q_9Y"
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2uYp7lxuXK3"
   },
   "outputs": [],
   "source": [
    "train_x = np.expand_dims(train_x, axis=2)\n",
    "test_x = np.expand_dims(test_x, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlbBZE79unrV"
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bPyg3Y4uqMR"
   },
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XGlrnVdsNpY"
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y,\n",
    "          validation_data=(test_x, test_y),\n",
    "          epochs=20, \n",
    "          batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eQv25sVsLSE"
   },
   "outputs": [],
   "source": [
    "#Model Prediction on first example\n",
    "a = model.predict(test_x[0:1])\n",
    "print('Normalized Prediction', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aye03H6gSTLy"
   },
   "outputs": [],
   "source": [
    "print('De-normalized Prediction', a * std + mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKbmpOpLSbpw"
   },
   "outputs": [],
   "source": [
    "#Actual \n",
    "test_y[0]*std+mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwJRhkD6wEkC"
   },
   "source": [
    "Visualize Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AO6Ux1dvmC2"
   },
   "outputs": [],
   "source": [
    "#Pick a test example\n",
    "exp_num = np.random.randint(0, test_x.shape[0])\n",
    "\n",
    "#Make input example a batch of 1\n",
    "prediction = model.predict(np.expand_dims(test_x[exp_num], axis=0))\n",
    "\n",
    "#Visualize\n",
    "show_example(test_x[exp_num], test_y[exp_num], prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdN3qW-G9y4M"
   },
   "source": [
    "#### Mutiple Time Series - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dst_kHm91rc"
   },
   "outputs": [],
   "source": [
    "#Air tempreture, pressure and air density\n",
    "features_to_include = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n",
    "\n",
    "#Get data\n",
    "multi_df = df[features_to_include]\n",
    "multi_df.index = df['Date Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "we_81mhYos_0"
   },
   "outputs": [],
   "source": [
    "multi_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ij9w7cPBo8Pl"
   },
   "outputs": [],
   "source": [
    "num_training_examples = int(0.8 * multi_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61vQBnLD-aXU"
   },
   "outputs": [],
   "source": [
    "#Train and Test data\n",
    "train_df = multi_df.iloc[:num_training_examples,:]\n",
    "test_df = multi_df.iloc[num_training_examples:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCx-6RA1-uoC"
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nep8UWLT-0r6"
   },
   "source": [
    "Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c14c2zq6-xu1"
   },
   "outputs": [],
   "source": [
    "#Find mean and standard deviation\n",
    "mean_multi = train_df.mean()\n",
    "std_multi = train_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKq2CKdl-5ya"
   },
   "outputs": [],
   "source": [
    "mean_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1wWrLep_JTW"
   },
   "outputs": [],
   "source": [
    "std_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsNUiFSv_NMV"
   },
   "outputs": [],
   "source": [
    "#Normalize Train and Test data\n",
    "norm_train_df = (train_df - mean_multi)/std_multi\n",
    "norm_test_df = (test_df - mean_multi)/std_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w87oPIdL_VCB"
   },
   "outputs": [],
   "source": [
    "norm_train_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfCG9Sbf_nsj"
   },
   "source": [
    "Prepare X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KQYs3Ti_iJN"
   },
   "outputs": [],
   "source": [
    "def prepare_xy_multi(dataset, num_time_series=3, window_size=[20,15,10], target_series=0):\n",
    "\n",
    "    dataX, dataY = [], []\n",
    "\n",
    "    act_data = []\n",
    "\n",
    "    for i in range(num_time_series):\n",
    "        dataX.append([]) #Initialize an empty list for each time series\n",
    "        act_data.append(dataset.iloc[:,i].to_list())\n",
    "\n",
    "    #Get max window size\n",
    "    max_window_size = max(window_size)\n",
    "\n",
    "    for i in range(len(dataset)-max_window_size):\n",
    "        \n",
    "        #Prepare input for each time series\n",
    "        for j in range(num_time_series):\n",
    "\n",
    "            #Prepare input features\n",
    "            input_features = act_data[j][(i+max_window_size-window_size[j]):(i+max_window_size)]\n",
    "            dataX[j].append(input_features)\n",
    "\n",
    "        #Prepare Label\n",
    "        label = act_data[target_series][i + max_window_size]\n",
    "        dataY.append(label)\n",
    "    \n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27_Na2_jBQLW"
   },
   "outputs": [],
   "source": [
    "#Prepare Training and Test X, y\n",
    "train_x_multi, train_y_multi = prepare_xy_multi(norm_train_df)\n",
    "test_x_multi, test_y_multi = prepare_xy_multi(norm_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOUi2pTXBwMx"
   },
   "outputs": [],
   "source": [
    "len(train_x_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiskaI1g-UyP"
   },
   "outputs": [],
   "source": [
    "train_x_multi[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_Ry7JKCFHya"
   },
   "source": [
    "#### Build Model II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AFWVP3kp_sq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ycup7zqKFK5P"
   },
   "outputs": [],
   "source": [
    "#Build 3 input layers - one for each time series\n",
    "input_1 = tf.keras.layers.Input(shape=(20,1)) #Tempreture\n",
    "input_2 = tf.keras.layers.Input(shape=(15,1)) #Pressure\n",
    "input_3 = tf.keras.layers.Input(shape=(10,1)) #Relative humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Er732Ic1Fm5u"
   },
   "outputs": [],
   "source": [
    "#Build 3 LSTM Layers - One for each time series\n",
    "lstm_1 = tf.keras.layers.LSTM(8)(input_1)\n",
    "lstm_2 = tf.keras.layers.LSTM(6)(input_2)\n",
    "lstm_3 = tf.keras.layers.LSTM(5)(input_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhaC3-Csuakd"
   },
   "outputs": [],
   "source": [
    "lstm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "255NHjJCDeKX"
   },
   "outputs": [],
   "source": [
    "lstm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLi7SmPuBWOr"
   },
   "outputs": [],
   "source": [
    "lstm_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqPAeGmOF48D"
   },
   "outputs": [],
   "source": [
    "#Concatenate LSTM layers output\n",
    "cat = tf.keras.layers.concatenate([lstm_1, lstm_2, lstm_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZ62gahlGFv6"
   },
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSZOsGivGHYP"
   },
   "outputs": [],
   "source": [
    "#Output Layer\n",
    "op = tf.keras.layers.Dense(1)(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Brq7M7mTqk2h"
   },
   "outputs": [],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpxgSvz1GNUu"
   },
   "outputs": [],
   "source": [
    "#Build Non-Sequential Model\n",
    "model_multi = tf.keras.Model([input_1, input_2, input_3], #3 Inputs\n",
    "                             op) #Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFKmR18FGdO0"
   },
   "outputs": [],
   "source": [
    "#compile model \n",
    "model_multi.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thT_tSImqtVN"
   },
   "outputs": [],
   "source": [
    "model_multi.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vD8_Mbr0Gm-M"
   },
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M__bvuk0GySk"
   },
   "source": [
    "We need to feed 3 inputs. Each input will be 3 dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SWP2u8KG3Gd"
   },
   "outputs": [],
   "source": [
    "#Build data for training\n",
    "train_x_multi_1 = np.reshape(np.array(train_x_multi[0]), (len(train_x_multi[0]),len(train_x_multi[0][1]),1 ))\n",
    "train_x_multi_2 = np.reshape(np.array(train_x_multi[1]), (len(train_x_multi[1]),len(train_x_multi[1][1]),1 ))\n",
    "train_x_multi_3 = np.reshape(np.array(train_x_multi[2]), (len(train_x_multi[2]),len(train_x_multi[2][1]),1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bdjkAeQH1WN"
   },
   "outputs": [],
   "source": [
    "train_x_multi_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcU5QwTVIHi-"
   },
   "outputs": [],
   "source": [
    "#Build data for test\n",
    "test_x_multi_1 = np.reshape(np.array(test_x_multi[0]), (len(test_x_multi[0]),len(test_x_multi[0][1]),1 ))\n",
    "test_x_multi_2 = np.reshape(np.array(test_x_multi[1]), (len(test_x_multi[1]),len(test_x_multi[1][1]),1 ))\n",
    "test_x_multi_3 = np.reshape(np.array(test_x_multi[2]), (len(test_x_multi[2]),len(test_x_multi[2][1]),1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2mB5ACHvQN7"
   },
   "outputs": [],
   "source": [
    "test_x_multi_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6JaRoa-Gri6"
   },
   "outputs": [],
   "source": [
    "#Model training\n",
    "model_multi.fit([train_x_multi_1, train_x_multi_2, train_x_multi_3], np.array(train_y_multi), \n",
    "                validation_data=([test_x_multi_1, test_x_multi_2, test_x_multi_3], np.array(test_y_multi)), \n",
    "                epochs=10, \n",
    "                batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZIjnsQwJoWb"
   },
   "source": [
    "Visualize Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yw3a_7jvIke3"
   },
   "outputs": [],
   "source": [
    "#Pick a test example\n",
    "exp_num = np.random.randint(0, len(test_y_multi))\n",
    "\n",
    "#Prepare 3 batch inputs - each 3 dimensional\n",
    "in_1 = np.expand_dims(np.array(test_x_multi[0][exp_num]), axis=0)\n",
    "in_2 = np.expand_dims(np.array(test_x_multi[1][exp_num]), axis=0)\n",
    "in_3 = np.expand_dims(np.array(test_x_multi[2][exp_num]), axis=0)\n",
    "\n",
    "#print(in_1.shape, in_2.shape)\n",
    "#Make prediction\n",
    "prediction = model_multi.predict([in_1, in_2, in_3])\n",
    "\n",
    "#Visualize\n",
    "show_example(in_1[0], test_y_multi[exp_num], prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwU_2jfCjv49"
   },
   "source": [
    "Using Single LSTM with same time window for multiple time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qo1DUq3pjn1J"
   },
   "outputs": [],
   "source": [
    "train_x_multi, train_y_multi = prepare_xy_multi(norm_train_df, window_size=(20,20,20))\n",
    "test_x_multi, test_y_multi = prepare_xy_multi(norm_test_df, window_size=(20,20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sr9VopvDGXam"
   },
   "outputs": [],
   "source": [
    "train_x = np.concatenate([np.reshape(train_x_multi[0], (-1, 20,1)), \n",
    "                          np.reshape(train_x_multi[1], (-1, 20,1)), \n",
    "                          np.reshape(train_x_multi[2], (-1, 20,1))], axis=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MH7Sw1gTGwvg"
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWwZfTAyHjNK"
   },
   "outputs": [],
   "source": [
    "test_x = np.concatenate([np.reshape(test_x_multi[0], (-1, 20,1)), \n",
    "                          np.reshape(test_x_multi[1], (-1, 20,1)), \n",
    "                          np.reshape(test_x_multi[2], (-1, 20,1))], axis=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCWRE_aKHoBx"
   },
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8VLmiRRHpUN"
   },
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-OtiKaXHsZB"
   },
   "outputs": [],
   "source": [
    "model1.add(tf.keras.layers.LSTM(8, input_shape=(20,3,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRhgKqCvH0y3"
   },
   "outputs": [],
   "source": [
    "model1.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBmEG_fnH7b4"
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptttB1hRIAwK"
   },
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vDlRpsUICdd"
   },
   "outputs": [],
   "source": [
    "model1.fit(train_x, np.array(train_y_multi), epochs=5, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdLWLjkwkphD"
   },
   "outputs": [],
   "source": [
    "#Pick a test example\n",
    "exp_num = np.random.randint(0, test_x.shape[0])\n",
    "\n",
    "#Prepare 3 batch inputs - each 3 dimensional\n",
    "in_1 = np.expand_dims(test_x[exp_num], axis=0)\n",
    "\n",
    "#Make prediction\n",
    "prediction = model1.predict(in_1)\n",
    "\n",
    "#Visualize\n",
    "#show_example(in_1[0], test_y_multi[exp_num], prediction[0])\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPSJtQdSQdr262myEMcJy9j",
   "collapsed_sections": [
    "b8ewHTEJUO-0",
    "lwKs9c39VLNJ",
    "dJi2VdvRYowB",
    "mvm_3cypaexT",
    "XOrQuVVNoZVs",
    "VdN3qW-G9y4M",
    "w_Ry7JKCFHya",
    "vD8_Mbr0Gm-M"
   ],
   "name": "Time-Series with RNN : Weather Forecast v2.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
