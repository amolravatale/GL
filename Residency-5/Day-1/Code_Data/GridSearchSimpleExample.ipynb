{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,2:]\n",
    "y = iris.target\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)  # split into 75:25 by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "### Number of nearest neighbors\n",
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best score: 0.97\n",
      " Best parameters: {' n_neighbors': 3, 'algorithm': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "# To evaluate all the hyper parameter combinations we can write a nested for loops as below \n",
    "best_score = 0\n",
    "for nn in [2, 3, 4, 5, 6, 7, 8, 9]: \n",
    "    for algo in ['auto', 'ball_tree', 'kd_tree', 'brute']: \n",
    "        # for each combination of parameters, train a model \n",
    "        knn_clf = KNeighborsClassifier(n_neighbors = nn , algorithm = algo)\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        # evaluate the model on the test data\n",
    "        score = knn_clf.score( X_test, y_test) \n",
    "        # if the score is higher than previous iteration score, store the score and parameters \n",
    "        if score > best_score: \n",
    "            best_score = score \n",
    "            best_parameters = {' n_neighbors': nn, 'algorithm': algo} \n",
    "            \n",
    "            \n",
    "print(\" Best score: {:.2f}\".format( best_score)) \n",
    "print(\" Best parameters: {}\".format( best_parameters))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem with this approach it is not reliable as it is based on only one test data\n",
    "# and the best hyper parameter values are influenced by test data \n",
    "# Instead we can split data into three parts - Training, Validation and Testing. Do the hyper parameter evaluation on training \n",
    "# and validation data. Check the best hyper parameters on the test set.  \n",
    "# When we split data into three and sample is small, this reduced the number of data points available for training!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': list(range(2,9)) , 'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(knn_clf,param_grid,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='brute', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=9, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
       "                         'n_neighbors': [2, 3, 4, 5, 6, 7, 8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto', 'n_neighbors': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_    # Check if this is the same combination obtained thru one single train test above in the for next loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_   # To obtain an instance of the model with the best hyper parameters. This is automatically copied /used to\n",
    "                     # update our model with the best hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'algorithm': 'auto', 'n_neighbors': 2},\n",
       " {'algorithm': 'auto', 'n_neighbors': 3},\n",
       " {'algorithm': 'auto', 'n_neighbors': 4},\n",
       " {'algorithm': 'auto', 'n_neighbors': 5},\n",
       " {'algorithm': 'auto', 'n_neighbors': 6},\n",
       " {'algorithm': 'auto', 'n_neighbors': 7},\n",
       " {'algorithm': 'auto', 'n_neighbors': 8},\n",
       " {'algorithm': 'ball_tree', 'n_neighbors': 2},\n",
       " {'algorithm': 'ball_tree', 'n_neighbors': 3},\n",
       " {'algorithm': 'ball_tree', 'n_neighbors': 4},\n",
       " {'algorithm': 'ball_tree', 'n_neighbors': 5},\n",
       " {'algorithm': 'ball_tree', 'n_neighbors': 6},\n",
       " {'algorithm': 'ball_tree', 'n_neighbors': 7},\n",
       " {'algorithm': 'ball_tree', 'n_neighbors': 8},\n",
       " {'algorithm': 'kd_tree', 'n_neighbors': 2},\n",
       " {'algorithm': 'kd_tree', 'n_neighbors': 3},\n",
       " {'algorithm': 'kd_tree', 'n_neighbors': 4},\n",
       " {'algorithm': 'kd_tree', 'n_neighbors': 5},\n",
       " {'algorithm': 'kd_tree', 'n_neighbors': 6},\n",
       " {'algorithm': 'kd_tree', 'n_neighbors': 7},\n",
       " {'algorithm': 'kd_tree', 'n_neighbors': 8},\n",
       " {'algorithm': 'brute', 'n_neighbors': 2},\n",
       " {'algorithm': 'brute', 'n_neighbors': 3},\n",
       " {'algorithm': 'brute', 'n_neighbors': 4},\n",
       " {'algorithm': 'brute', 'n_neighbors': 5},\n",
       " {'algorithm': 'brute', 'n_neighbors': 6},\n",
       " {'algorithm': 'brute', 'n_neighbors': 7},\n",
       " {'algorithm': 'brute', 'n_neighbors': 8}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95606061, 0.94621212, 0.9469697 , 0.95530303, 0.95530303,\n",
       "       0.95530303, 0.95530303, 0.95606061, 0.94621212, 0.9469697 ,\n",
       "       0.95530303, 0.95530303, 0.95530303, 0.95530303, 0.95606061,\n",
       "       0.94621212, 0.9469697 , 0.95530303, 0.95530303, 0.95530303,\n",
       "       0.95530303, 0.9469697 , 0.94621212, 0.9469697 , 0.95530303,\n",
       "       0.95530303, 0.95530303, 0.94621212])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_['mean_test_score']  # These scores are more reliable as they are the averaged output of CV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model as the final model\n",
    "\n",
    "final_model = gs.best_estimator_   # Note: This is done automatically if the refit option is true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.score(X_test , y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
