{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmsk5ao7SKPE"
   },
   "source": [
    "#### Connect to Kaggle\n",
    "\n",
    "Data is available on Kaggle website. We will first connect Colab to Kaggle. Instructions for downloading kaggle data to Colab can be found [in this post](https://towardsdatascience.com/setting-up-kaggle-in-google-colab-ebb281b61463)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RHs1yFqPui4"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN8aIfdsTL5x"
   },
   "outputs": [],
   "source": [
    "#Make a directory for Kaggle\n",
    "!mkdir .kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7S6ZzzME0R-"
   },
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-f7PDwsXSrme"
   },
   "outputs": [],
   "source": [
    "#Connect Google drive to colab\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_tzOnovSt_2"
   },
   "outputs": [],
   "source": [
    "#Copy kaggle.json file. Change gdrive folder based on where you have saved your json file from Kaggle\n",
    "!cp '/gdrive/My Drive/AI-ML/Machine-Learning/Code/Utilities/kaggle.json' /content/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opbERS-qGKC7"
   },
   "outputs": [],
   "source": [
    "#Check if json file is there\n",
    "!ls -l /content/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXasaMMfGSYE"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vv2P_g8GU_CW"
   },
   "outputs": [],
   "source": [
    "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GU8VabPrUMmG"
   },
   "outputs": [],
   "source": [
    "!kaggle config set -n path -v{/content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUlJ_WSkVA8J"
   },
   "outputs": [],
   "source": [
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zez4Y6ReVna-"
   },
   "source": [
    "Verify Kaggle connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQr_FRo2Vp1N"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MWBgMpKaVazv"
   },
   "source": [
    "#### Download TGS Dataset\n",
    "\n",
    "Here is the [link](https://www.kaggle.com/c/tgs-salt-identification-challenge/data) for TGS Salt identification competition. You may need to agree to the rules of the competition before download is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdw3P9V9VuAe"
   },
   "outputs": [],
   "source": [
    "#Download data from Kaggle for TGS Salt and copy it to /content folder\n",
    "!kaggle competitions download -c tgs-salt-identification-challenge -p /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMYKmyKdXKey"
   },
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvUWe5HNYxi-"
   },
   "outputs": [],
   "source": [
    "#unzip training data\n",
    "!unzip train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oe3Gx118vnMA"
   },
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNh2k-MTs7Kc"
   },
   "outputs": [],
   "source": [
    "!ls -l images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcuOZZ1vaSII"
   },
   "outputs": [],
   "source": [
    "!ls -l masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KblkZlmEYFg-"
   },
   "source": [
    "Images and Masks are unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14CoGh6cXgGp"
   },
   "outputs": [],
   "source": [
    "!ls -l images | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZkU-a3wWOpw"
   },
   "outputs": [],
   "source": [
    "!ls -l masks | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFo4n2BcYedM"
   },
   "source": [
    "#### Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-oDd72zQYgJB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knAsNl78zH2O"
   },
   "source": [
    "Read training images and build a dataframe with IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "134AWxJW3kfm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQ9qdY2BICIh"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUelt28h0gC2"
   },
   "source": [
    "Split training data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TN7GLO140iJQ"
   },
   "outputs": [],
   "source": [
    "idx = np.random.rand(len(df)) < 0.8\n",
    "test_df = df[~idx]\n",
    "train_df = df[idx]\n",
    "test_df.reset_index(inplace=True)\n",
    "train_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcRD7j4KIQmE"
   },
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5_69qN0ZsJ6"
   },
   "outputs": [],
   "source": [
    "def display_seismic_data(img_num, df):\n",
    "\n",
    "    #Create a pyplot with two images\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 8))\n",
    "\n",
    "    #Read Seismic image and corresponding mask\n",
    "    seismic_img = tf.keras.preprocessing.image.load_img('images/' + df.loc[img_num, 'id'] + '.png', color_mode='grayscale')\n",
    "\n",
    "    mask_img = tf.keras.preprocessing.image.load_img('masks/' + df.loc[img_num, 'id'] + '.png', color_mode='grayscale')\n",
    "    \n",
    "    #Show both images\n",
    "    ax1.set_title('Seismic')\n",
    "    ax1.imshow(seismic_img, cmap = 'seismic', interpolation = 'bilinear')\n",
    "    ax1.axis('off')\n",
    "    ax2.set_title('Salt')\n",
    "    ax2.imshow(mask_img, cmap = 'gray', interpolation = 'bilinear')\n",
    "    #ax2.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdEkrp_MeArJ"
   },
   "outputs": [],
   "source": [
    "#Try random images\n",
    "img_num = np.random.randint(0, train_df.shape[0])\n",
    "display_seismic_data(img_num, train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3DGC2ODvQJR"
   },
   "source": [
    "#### Build Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1uGqnTvvSUn"
   },
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fcg1SjtwvU2T"
   },
   "outputs": [],
   "source": [
    "def batch_generator(df, batch_size=32):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        #Create random indexes\n",
    "        idx = np.random.randint(0, df.shape[0], batch_size)\n",
    "\n",
    "        #Initialize numpy arrays for X and y\n",
    "        #Input image is size img_size,img_size,1\n",
    "        X = np.zeros((batch_size, img_size, img_size,1))\n",
    "        #Mask's size is img_size, img_size, 1\n",
    "        y = np.zeros((batch_size, img_size, img_size,num_classes))\n",
    "\n",
    "        #Populate X and y with actual data\n",
    "        for i in range(len(idx)):\n",
    "\n",
    "            #Read image\n",
    "            img = tf.keras.preprocessing.image.load_img('images/' + df.loc[idx[i],'id'] + '.png', color_mode='grayscale',\n",
    "                                                        target_size=(img_size, img_size))\n",
    "            img = tf.keras.preprocessing.image.img_to_array(img).astype('uint8')/255.0\n",
    "\n",
    "            X[i] = img\n",
    "\n",
    "            #Read mask\n",
    "            mask_img = tf.keras.preprocessing.image.load_img('masks/' + df.loc[idx[i],'id'] + '.png',\n",
    "                                                            color_mode = 'grayscale',\n",
    "                                                            target_size=(img_size, img_size))\n",
    "            mask_img = tf.keras.preprocessing.image.img_to_array(mask_img).astype('uint8')/255.0\n",
    "            \n",
    "            #One hot encoding\n",
    "            mask_img = tf.keras.utils.to_categorical(mask_img, num_classes=num_classes)\n",
    "\n",
    "            y[i] = mask_img\n",
    "\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBvPLdoguDRR"
   },
   "outputs": [],
   "source": [
    "a = batch_generator(df, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpuau0fJLbFj"
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwxcLUmXuKNx"
   },
   "outputs": [],
   "source": [
    "x, y = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hliBNZvnuMMU"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RF2QgkRF78so"
   },
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZIrPSZ9bdcn"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9a-4hLBEuPsp"
   },
   "outputs": [],
   "source": [
    "np.unique(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYayHQjwpz5c"
   },
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayqMFpIxp2Yo"
   },
   "source": [
    "Function to create two Convolutional layer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSB1lpP8q_B4"
   },
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = tf.keras.layers.Conv2D(n_filters, (3,3), kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = tf.keras.layers.Conv2D(n_filters, (3,3), kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCliarJNsMt1"
   },
   "source": [
    "Function to build UNET Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-L8VpW28sKS9"
   },
   "outputs": [],
   "source": [
    "def build_unet(input_img, n_filters=16, dropout=0.1):\n",
    "\n",
    "    #ENCODER - DOWNSAMPLE the image - 128x128x1\n",
    "\n",
    "    #First Block\n",
    "    c1 = conv2d_block(input_img, n_filters*1) #128x128x16\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1) #64x64x16\n",
    "    p1 = tf.keras.layers.Dropout(dropout)(p1) #64x64x16\n",
    "    #output will be 64x64x16 for image size 128x128x1\n",
    "\n",
    "    #Second Block\n",
    "    c2 = conv2d_block(p1, n_filters*2) #64x64x32\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2) #32x32x32\n",
    "    p2 = tf.keras.layers.Dropout(dropout)(p2)\n",
    "    #output will be 32x32x32\n",
    "\n",
    "    #Third Block\n",
    "    c3 = conv2d_block(p2, n_filters*4) #32x32x64\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3) #16x16x64\n",
    "    p3 = tf.keras.layers.Dropout(dropout)(p3)\n",
    "    #output will be 16x16x64\n",
    "\n",
    "    #Fourth Block\n",
    "    c4 = conv2d_block(p3, n_filters*8) #16x16x128\n",
    "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "    p4 = tf.keras.layers.Dropout(dropout)(p4)\n",
    "    ##output will be 8x8x128 \n",
    "\n",
    "    #Fifth Block\n",
    "    c5 = conv2d_block(p4, n_filters*16)\n",
    "    #output will be 8x8x256\n",
    "\n",
    "    #We now have output of Encoder\n",
    "\n",
    "    #DECODER - UPSAMPLE the feature to generate mask\n",
    "\n",
    "    #First Block - connected to fourth block on DOWNSAMPLE side\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(n_filters * 8, (3, 3), \n",
    "                                         strides = (2, 2), \n",
    "                                         padding = 'same')(c5) #16x16x128\n",
    "    #Skip connection\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4]) #16x16x256\n",
    "    u6 = tf.keras.layers.Dropout(dropout)(u6) \n",
    "    c6 = conv2d_block(u6, n_filters * 8) #16x16x128\n",
    "\n",
    "    #Second Block - connected to third block on DOWNSAMPLE side\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6) #32x32x64\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    u7 = tf.keras.layers.Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4)\n",
    "\n",
    "    #Third Block - connected to second block on DOWNSAMPLE side\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7) #64x64x32\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    u8 = tf.keras.layers.Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2) \n",
    "\n",
    "    #Fourth Block - connected to first block on DOWNSAMPLE side\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8) #128x128x16\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1])\n",
    "    u9 = tf.keras.layers.Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1) #128 x 128 x 16\n",
    "\n",
    "    #Build the Output layer\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, (1, 1), activation='softmax')(c9) #128x128x2\n",
    "\n",
    "    #Build the model using different layers\n",
    "    model = tf.keras.Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVDUgizjvGm6"
   },
   "source": [
    "Build UNET model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRGoM5_zvEQB"
   },
   "outputs": [],
   "source": [
    "#Clear out notebook session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "#Define input layer\n",
    "input_img = tf.keras.layers.Input((img_size, img_size, 1), name='input_img')\n",
    "\n",
    "#Build model\n",
    "model = build_unet(input_img, dropout=.3)\n",
    "\n",
    "#Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFK7c8BPVmFq"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DL6lFjwPyR6r"
   },
   "source": [
    "Build training and test batch generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_6472sGyUVt"
   },
   "outputs": [],
   "source": [
    "train_generator = batch_generator(train_df,batch_size=32)\n",
    "test_generator = batch_generator(test_df, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jxkH40ROmZr"
   },
   "outputs": [],
   "source": [
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FbhBN2aOq0h"
   },
   "outputs": [],
   "source": [
    "test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv42Vqy65VT6"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlbhbtCZyqeZ"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('TGS_v1.h5', save_best_only=True, monitor='val_accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNIv4BCc4xjS"
   },
   "outputs": [],
   "source": [
    "model.fit(train_generator,\n",
    "          steps_per_epoch=train_df.shape[0]//32, \n",
    "          validation_data=test_generator, \n",
    "          validation_steps=test_df.shape[0]//32, \n",
    "          callbacks=[model_checkpoint],\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDgS-vydTlbP"
   },
   "outputs": [],
   "source": [
    "#Load the best model\n",
    "model = tf.keras.models.load_model('/gdrive/My Drive/TGS_v1.h5')\n",
    "#model = tf.keras.models.load_model('TGS_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vysp8ixPTt9n"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erHNjYej7wXw"
   },
   "source": [
    "#### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-RQhs4x7x63"
   },
   "outputs": [],
   "source": [
    "def display_model_prediction(img_num, df):\n",
    "\n",
    "    #Read Seismic image and corresponding mask\n",
    "    seismic_img = tf.keras.preprocessing.image.load_img('images/' + df.loc[img_num, 'id'] + '.png', color_mode='grayscale')\n",
    "    mask_img = tf.keras.preprocessing.image.load_img('masks/' + df.loc[img_num, 'id'] + '.png', color_mode='grayscale')\n",
    "\n",
    "    #Model prediction\n",
    "    test_img = seismic_img.resize((img_size, img_size))\n",
    "    test_img = tf.keras.preprocessing.image.img_to_array(test_img).astype('uint8')/255.0\n",
    "    test_img = np.expand_dims(test_img, axis=0) #1,128,128,1\n",
    "\n",
    "    pred = model.predict(test_img) #1,128,128,num_classes\n",
    "    \n",
    "    predicted_classes = np.argmax(pred[0], axis=-1)\n",
    "    \n",
    "    #Create a pyplot with two images\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (12, 8))\n",
    "\n",
    "    #Show both images\n",
    "    ax1.set_title('Seismic')\n",
    "    ax1.imshow(seismic_img.resize((img_size, img_size)), cmap = 'seismic', interpolation = 'bilinear')\n",
    "    ax2.set_title('Actual Salt')\n",
    "    ax2.imshow(mask_img.resize((img_size, img_size)), cmap = 'gray', interpolation = 'bilinear')\n",
    "    ax3.set_title('Predicted Salt')\n",
    "    ax3.imshow(np.reshape(predicted_classes,(img_size, img_size)), cmap = 'gray', interpolation = 'bilinear')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xDWMQF_8dAp"
   },
   "outputs": [],
   "source": [
    "img_num = np.random.randint(0, test_df.shape[0])\n",
    "display_model_prediction(img_num, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpqfsHQaVg9g"
   },
   "outputs": [],
   "source": [
    "#model.save('/gdrive/My Drive/TGS_v1.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "H3DGC2ODvQJR",
    "IYayHQjwpz5c",
    "erHNjYej7wXw"
   ],
   "name": "1. Semantic Segmentation using UNET: TGS multi.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
