{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab_HandsOn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOH7EHezdEunD497IGf2EQW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"cGX7HY29CsVR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":82},"outputId":"e6aeb7f8-ecd1-4e47-cc68-b97c9c630dcf","executionInfo":{"status":"ok","timestamp":1578770540534,"user_tz":-330,"elapsed":2797,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler\n","import tensorflow as tf\n","from keras.utils import np_utils"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"CVlXeWstDued","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":128},"outputId":"545af3a2-5f0f-478e-dc38-dce6ff7fe96f","executionInfo":{"status":"ok","timestamp":1578770605212,"user_tz":-330,"elapsed":43765,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["#Mount Google drive\n","from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NhYEvx9fDuhv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":235},"outputId":"22942772-fa86-40e8-bc79-21b96901d1f5","executionInfo":{"status":"ok","timestamp":1578770615448,"user_tz":-330,"elapsed":4226,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["!ls \"/gdrive/My Drive/classNotes/introNN/Notebooks/\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["'1. Tensorflow_Hello_World_tf2.ipynb'\n","'2a. Boston Housing Prices.ipynb'\n","'2b. Boston Housing Prices_Normalization.ipynb'\n","'3. Boston_Housing_Prices_KERAS.ipynb'\n","'4. Classification_MNIST_Logistic_Keras.ipynb'\n","'5. Classification_MNIST_Logistic_Keras_batching.ipynb'\n","'6. Classification_MNIST_DNN_Keras.ipynb'\n","'7. MNIST_Prediction.ipynb'\n"," boston_housing_lr.h5\n"," google.csv\n"," Lab2_stockDirection_modelsComparison_v1.py\n"," Lab_HandsOn.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ddM1xVl0Dunl","colab_type":"code","colab":{}},"source":["dataPath = \"/gdrive/My Drive/classNotes/introNN/Notebooks/google.csv\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLleuWHFDutp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"cdfa0b84-ee39-4ee3-8a19-f34e8d1a208e","executionInfo":{"status":"ok","timestamp":1578770666443,"user_tz":-330,"elapsed":1361,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["df = pd.read_csv(dataPath)\n","df.columns"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['date', 'open', 'high', 'low', 'volume', 'close', 'direction'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"tpjdLC80Duwb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"018990ac-d1a4-43c6-a281-ba5b491c08b4","executionInfo":{"status":"ok","timestamp":1578770697470,"user_tz":-330,"elapsed":1026,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["train_size = 2000\n","#Split the data\n","train = df.loc[0:train_size, :]\n","test = df.loc[(train_size+1):, :]\n","print('train: {}\\ntest: {}'.format(len(train), len(test)))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["train: 2001\n","test: 829\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9MdShPqJDu2u","colab_type":"code","colab":{}},"source":["X_train = train[['open', 'close']]\n","y_train = train[['direction']]\n","X_test = test[['open', 'close']]\n","y_test = test[['direction']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVafOgLzDuqc","colab_type":"code","colab":{}},"source":["scaler = MinMaxScaler()\n","X_train = scaler.fit_transform(X_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e45lnwy3EasI","colab_type":"code","colab":{}},"source":["X_test = scaler.transform(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rv_VTf7Eavh","colab_type":"code","colab":{}},"source":["###################### Classical machine learning\n","# Logistic regression\n","# Naive Bayes\n","# K-nearest neighbors\n","# Support Vector Machines\n","# Decision trees\n","# Random Forest"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4mfRFW1XEazA","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2FAcf_LuEa1q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":327},"outputId":"70d6df67-518b-4c41-8671-93a4fd634d76","executionInfo":{"status":"ok","timestamp":1578770793193,"user_tz":-330,"elapsed":1741,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["models = []\n","models.append(('LR', LogisticRegression()))\n","models.append(('NB', GaussianNB()))\n","models.append(('KNN', KNeighborsClassifier()))\n","models.append(('SVM', SVC()))\n","models.append(('CART', DecisionTreeClassifier(max_depth=10)))\n","models.append(('RF', RandomForestClassifier()))\n","# evaluate each model in turn\n","results = []\n","names = []\n","for name, model in models:\n","    model = model.fit(X_train, y_train)\n","    msg = \"%s: %f (%f) \" % (name, model.score(X_train, y_train), model.score(X_test, y_test))\n","    print(msg)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["LR: 0.633183 (0.566948) \n","NB: 0.511744 (0.469240) \n","KNN: 0.850575 (0.787696) \n","SVM: 0.665167 (0.558504) \n","CART: 0.660670 (0.534379) \n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  if sys.path[0] == '':\n"],"name":"stderr"},{"output_type":"stream","text":["RF: 1.000000 (0.585042) \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2AX6bksYEa5H","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-lGe41NREro6","colab_type":"text"},"source":["# Build a neural network model to predict the direction of the stock"]},{"cell_type":"code","metadata":{"id":"2EKOCx6xFHLX","colab_type":"code","colab":{}},"source":["num_classes = 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kmp6tkE0GCSo","colab_type":"code","colab":{}},"source":["y_train = np_utils.to_categorical(y_train)\n","y_test = np_utils.to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iNtI3E5REa8R","colab_type":"code","colab":{}},"source":["model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(num_classes, input_shape=(X_train.shape[1],), activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJRSM5pGFWl1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"6e8d0697-4788-4cc1-d8e4-55f4040175c0","executionInfo":{"status":"ok","timestamp":1578771179997,"user_tz":-330,"elapsed":10746,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), batch_size=32)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Train on 2001 samples, validate on 829 samples\n","Epoch 1/100\n","2001/2001 [==============================] - 0s 138us/sample - loss: 0.6931 - acc: 0.5057 - val_loss: 0.7038 - val_acc: 0.4656\n","Epoch 2/100\n","2001/2001 [==============================] - 0s 48us/sample - loss: 0.6918 - acc: 0.5417 - val_loss: 0.6983 - val_acc: 0.4656\n","Epoch 3/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6913 - acc: 0.5327 - val_loss: 0.6939 - val_acc: 0.4668\n","Epoch 4/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6912 - acc: 0.5347 - val_loss: 0.6926 - val_acc: 0.4777\n","Epoch 5/100\n","2001/2001 [==============================] - 0s 46us/sample - loss: 0.6911 - acc: 0.5322 - val_loss: 0.6916 - val_acc: 0.5151\n","Epoch 6/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6911 - acc: 0.5357 - val_loss: 0.6904 - val_acc: 0.5344\n","Epoch 7/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6910 - acc: 0.5422 - val_loss: 0.6897 - val_acc: 0.5971\n","Epoch 8/100\n","2001/2001 [==============================] - 0s 47us/sample - loss: 0.6911 - acc: 0.5297 - val_loss: 0.6903 - val_acc: 0.5513\n","Epoch 9/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6910 - acc: 0.5162 - val_loss: 0.6885 - val_acc: 0.6248\n","Epoch 10/100\n","2001/2001 [==============================] - 0s 47us/sample - loss: 0.6910 - acc: 0.5172 - val_loss: 0.6890 - val_acc: 0.6719\n","Epoch 11/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6910 - acc: 0.5232 - val_loss: 0.6887 - val_acc: 0.6743\n","Epoch 12/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6910 - acc: 0.5302 - val_loss: 0.6881 - val_acc: 0.5730\n","Epoch 13/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6910 - acc: 0.5107 - val_loss: 0.6878 - val_acc: 0.5597\n","Epoch 14/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6909 - acc: 0.5082 - val_loss: 0.6876 - val_acc: 0.5513\n","Epoch 15/100\n","2001/2001 [==============================] - 0s 47us/sample - loss: 0.6909 - acc: 0.5107 - val_loss: 0.6882 - val_acc: 0.5983\n","Epoch 16/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6909 - acc: 0.5097 - val_loss: 0.6881 - val_acc: 0.6019\n","Epoch 17/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6908 - acc: 0.5092 - val_loss: 0.6875 - val_acc: 0.5513\n","Epoch 18/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6908 - acc: 0.5107 - val_loss: 0.6870 - val_acc: 0.5404\n","Epoch 19/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6908 - acc: 0.5092 - val_loss: 0.6875 - val_acc: 0.5549\n","Epoch 20/100\n","2001/2001 [==============================] - 0s 47us/sample - loss: 0.6908 - acc: 0.5287 - val_loss: 0.6875 - val_acc: 0.5549\n","Epoch 21/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6908 - acc: 0.5092 - val_loss: 0.6868 - val_acc: 0.5392\n","Epoch 22/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6909 - acc: 0.5307 - val_loss: 0.6874 - val_acc: 0.5513\n","Epoch 23/100\n","2001/2001 [==============================] - 0s 46us/sample - loss: 0.6907 - acc: 0.5087 - val_loss: 0.6868 - val_acc: 0.5392\n","Epoch 24/100\n","2001/2001 [==============================] - 0s 46us/sample - loss: 0.6907 - acc: 0.5087 - val_loss: 0.6871 - val_acc: 0.5489\n","Epoch 25/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6908 - acc: 0.5127 - val_loss: 0.6872 - val_acc: 0.5501\n","Epoch 26/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6908 - acc: 0.5792 - val_loss: 0.6869 - val_acc: 0.5452\n","Epoch 27/100\n","2001/2001 [==============================] - 0s 54us/sample - loss: 0.6907 - acc: 0.5092 - val_loss: 0.6864 - val_acc: 0.5392\n","Epoch 28/100\n","2001/2001 [==============================] - 0s 46us/sample - loss: 0.6907 - acc: 0.5087 - val_loss: 0.6865 - val_acc: 0.5392\n","Epoch 29/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6907 - acc: 0.5242 - val_loss: 0.6869 - val_acc: 0.5464\n","Epoch 30/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6907 - acc: 0.5102 - val_loss: 0.6860 - val_acc: 0.5344\n","Epoch 31/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6906 - acc: 0.5102 - val_loss: 0.6860 - val_acc: 0.5344\n","Epoch 32/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6907 - acc: 0.5162 - val_loss: 0.6862 - val_acc: 0.5392\n","Epoch 33/100\n","2001/2001 [==============================] - 0s 47us/sample - loss: 0.6906 - acc: 0.5157 - val_loss: 0.6861 - val_acc: 0.5392\n","Epoch 34/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6907 - acc: 0.5162 - val_loss: 0.6863 - val_acc: 0.5404\n","Epoch 35/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6906 - acc: 0.5092 - val_loss: 0.6858 - val_acc: 0.5344\n","Epoch 36/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6906 - acc: 0.5117 - val_loss: 0.6859 - val_acc: 0.5368\n","Epoch 37/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6906 - acc: 0.5112 - val_loss: 0.6859 - val_acc: 0.5368\n","Epoch 38/100\n","2001/2001 [==============================] - 0s 47us/sample - loss: 0.6906 - acc: 0.5092 - val_loss: 0.6857 - val_acc: 0.5344\n","Epoch 39/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6906 - acc: 0.5162 - val_loss: 0.6858 - val_acc: 0.5356\n","Epoch 40/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6905 - acc: 0.5197 - val_loss: 0.6860 - val_acc: 0.5392\n","Epoch 41/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6905 - acc: 0.5137 - val_loss: 0.6855 - val_acc: 0.5344\n","Epoch 42/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6906 - acc: 0.5082 - val_loss: 0.6855 - val_acc: 0.5344\n","Epoch 43/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6906 - acc: 0.5227 - val_loss: 0.6859 - val_acc: 0.5392\n","Epoch 44/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6905 - acc: 0.5212 - val_loss: 0.6854 - val_acc: 0.5344\n","Epoch 45/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6905 - acc: 0.5187 - val_loss: 0.6857 - val_acc: 0.5380\n","Epoch 46/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6905 - acc: 0.5377 - val_loss: 0.6853 - val_acc: 0.5344\n","Epoch 47/100\n","2001/2001 [==============================] - 0s 40us/sample - loss: 0.6905 - acc: 0.5172 - val_loss: 0.6857 - val_acc: 0.5392\n","Epoch 48/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6907 - acc: 0.5167 - val_loss: 0.6854 - val_acc: 0.5344\n","Epoch 49/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6904 - acc: 0.5207 - val_loss: 0.6854 - val_acc: 0.5344\n","Epoch 50/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6904 - acc: 0.5217 - val_loss: 0.6855 - val_acc: 0.5380\n","Epoch 51/100\n","2001/2001 [==============================] - 0s 46us/sample - loss: 0.6904 - acc: 0.5322 - val_loss: 0.6856 - val_acc: 0.5392\n","Epoch 52/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6905 - acc: 0.5152 - val_loss: 0.6853 - val_acc: 0.5344\n","Epoch 53/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6904 - acc: 0.5532 - val_loss: 0.6858 - val_acc: 0.5416\n","Epoch 54/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6905 - acc: 0.5472 - val_loss: 0.6855 - val_acc: 0.5392\n","Epoch 55/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6904 - acc: 0.5662 - val_loss: 0.6853 - val_acc: 0.5368\n","Epoch 56/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6903 - acc: 0.5212 - val_loss: 0.6851 - val_acc: 0.5344\n","Epoch 57/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6903 - acc: 0.5242 - val_loss: 0.6852 - val_acc: 0.5368\n","Epoch 58/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6903 - acc: 0.5207 - val_loss: 0.6852 - val_acc: 0.5368\n","Epoch 59/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6903 - acc: 0.5207 - val_loss: 0.6852 - val_acc: 0.5380\n","Epoch 60/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6904 - acc: 0.5727 - val_loss: 0.6855 - val_acc: 0.5404\n","Epoch 61/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6903 - acc: 0.5677 - val_loss: 0.6850 - val_acc: 0.5344\n","Epoch 62/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6902 - acc: 0.5227 - val_loss: 0.6848 - val_acc: 0.5344\n","Epoch 63/100\n","2001/2001 [==============================] - 0s 48us/sample - loss: 0.6903 - acc: 0.5232 - val_loss: 0.6849 - val_acc: 0.5344\n","Epoch 64/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6902 - acc: 0.5172 - val_loss: 0.6847 - val_acc: 0.5344\n","Epoch 65/100\n","2001/2001 [==============================] - 0s 46us/sample - loss: 0.6903 - acc: 0.5627 - val_loss: 0.6850 - val_acc: 0.5368\n","Epoch 66/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6902 - acc: 0.5227 - val_loss: 0.6848 - val_acc: 0.5344\n","Epoch 67/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6902 - acc: 0.5342 - val_loss: 0.6847 - val_acc: 0.5344\n","Epoch 68/100\n","2001/2001 [==============================] - 0s 46us/sample - loss: 0.6902 - acc: 0.5187 - val_loss: 0.6848 - val_acc: 0.5344\n","Epoch 69/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6902 - acc: 0.5537 - val_loss: 0.6847 - val_acc: 0.5344\n","Epoch 70/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6902 - acc: 0.5152 - val_loss: 0.6845 - val_acc: 0.5344\n","Epoch 71/100\n","2001/2001 [==============================] - 0s 48us/sample - loss: 0.6901 - acc: 0.5362 - val_loss: 0.6846 - val_acc: 0.5344\n","Epoch 72/100\n","2001/2001 [==============================] - 0s 46us/sample - loss: 0.6902 - acc: 0.5927 - val_loss: 0.6846 - val_acc: 0.5344\n","Epoch 73/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6901 - acc: 0.5282 - val_loss: 0.6846 - val_acc: 0.5344\n","Epoch 74/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6901 - acc: 0.5422 - val_loss: 0.6847 - val_acc: 0.5380\n","Epoch 75/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6901 - acc: 0.5257 - val_loss: 0.6844 - val_acc: 0.5344\n","Epoch 76/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6902 - acc: 0.5377 - val_loss: 0.6847 - val_acc: 0.5368\n","Epoch 77/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6902 - acc: 0.6622 - val_loss: 0.6849 - val_acc: 0.5404\n","Epoch 78/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6901 - acc: 0.5327 - val_loss: 0.6843 - val_acc: 0.5344\n","Epoch 79/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6901 - acc: 0.5427 - val_loss: 0.6846 - val_acc: 0.5380\n","Epoch 80/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6900 - acc: 0.5372 - val_loss: 0.6845 - val_acc: 0.5368\n","Epoch 81/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6900 - acc: 0.5242 - val_loss: 0.6844 - val_acc: 0.5356\n","Epoch 82/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6900 - acc: 0.5437 - val_loss: 0.6843 - val_acc: 0.5344\n","Epoch 83/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6901 - acc: 0.5187 - val_loss: 0.6844 - val_acc: 0.5368\n","Epoch 84/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6900 - acc: 0.5417 - val_loss: 0.6846 - val_acc: 0.5404\n","Epoch 85/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6901 - acc: 0.5432 - val_loss: 0.6844 - val_acc: 0.5380\n","Epoch 86/100\n","2001/2001 [==============================] - 0s 44us/sample - loss: 0.6900 - acc: 0.5257 - val_loss: 0.6845 - val_acc: 0.5392\n","Epoch 87/100\n","2001/2001 [==============================] - 0s 48us/sample - loss: 0.6900 - acc: 0.6402 - val_loss: 0.6846 - val_acc: 0.5404\n","Epoch 88/100\n","2001/2001 [==============================] - 0s 50us/sample - loss: 0.6900 - acc: 0.5292 - val_loss: 0.6842 - val_acc: 0.5344\n","Epoch 89/100\n","2001/2001 [==============================] - 0s 46us/sample - loss: 0.6900 - acc: 0.5767 - val_loss: 0.6844 - val_acc: 0.5392\n","Epoch 90/100\n","2001/2001 [==============================] - 0s 47us/sample - loss: 0.6899 - acc: 0.5552 - val_loss: 0.6842 - val_acc: 0.5368\n","Epoch 91/100\n","2001/2001 [==============================] - 0s 49us/sample - loss: 0.6899 - acc: 0.5357 - val_loss: 0.6842 - val_acc: 0.5368\n","Epoch 92/100\n","2001/2001 [==============================] - 0s 45us/sample - loss: 0.6899 - acc: 0.5727 - val_loss: 0.6841 - val_acc: 0.5368\n","Epoch 93/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6899 - acc: 0.5642 - val_loss: 0.6843 - val_acc: 0.5392\n","Epoch 94/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6899 - acc: 0.5262 - val_loss: 0.6840 - val_acc: 0.5344\n","Epoch 95/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6899 - acc: 0.5307 - val_loss: 0.6840 - val_acc: 0.5356\n","Epoch 96/100\n","2001/2001 [==============================] - 0s 43us/sample - loss: 0.6900 - acc: 0.6227 - val_loss: 0.6844 - val_acc: 0.5416\n","Epoch 97/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6899 - acc: 0.5417 - val_loss: 0.6838 - val_acc: 0.5344\n","Epoch 98/100\n","2001/2001 [==============================] - 0s 41us/sample - loss: 0.6898 - acc: 0.5227 - val_loss: 0.6841 - val_acc: 0.5392\n","Epoch 99/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6898 - acc: 0.5412 - val_loss: 0.6840 - val_acc: 0.5368\n","Epoch 100/100\n","2001/2001 [==============================] - 0s 42us/sample - loss: 0.6898 - acc: 0.5777 - val_loss: 0.6840 - val_acc: 0.5380\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f5d200e1dd8>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"FH-HM5GOFWzL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"a96f26e3-e7f5-4147-cf41-faed5eb11cf9","executionInfo":{"status":"ok","timestamp":1578771190452,"user_tz":-330,"elapsed":1014,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["loss_and_metrics = model.evaluate(X_train, y_train)\n","print(loss_and_metrics)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["2001/2001 [==============================] - 0s 26us/sample - loss: 0.6897 - acc: 0.5512\n","[0.6896916536138631, 0.5512244]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s9i6p5iFFdDB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"6bea31a9-cf17-452c-d603-a7a2e4420629","executionInfo":{"status":"ok","timestamp":1578771195309,"user_tz":-330,"elapsed":1056,"user":{"displayName":"D. Narayana","photoUrl":"","userId":"17572554762277395202"}}},"source":["loss_and_metrics = model.evaluate(X_test, y_test)\n","print(loss_and_metrics)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["829/829 [==============================] - 0s 32us/sample - loss: 0.6840 - acc: 0.5380\n","[0.6840430193988492, 0.5379976]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t-7G9MWtGSUz","colab_type":"text"},"source":["# Improve the accuracy of above neural network model"]}]}