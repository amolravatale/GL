{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras.optimizers import SGD \n",
    "from tensorflow.keras import utils \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "# define some hyper parameters \n",
    "batch_size = 100 \n",
    "n_inputs = 784 \n",
    "n_classes = 10 \n",
    "n_epochs = 10 \n",
    "\n",
    "# get the data \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() # reshape the two dimensional 28 x 28 pixels # sized images into a single vector of 784 pixels \n",
    "\n",
    "x_train = x_train.reshape( 60000, n_inputs) \n",
    "x_test = x_test.reshape( 10000, n_inputs) \n",
    "\n",
    "# convert the input values to float32 \n",
    "x_train = x_train.astype( np.float32) \n",
    "x_test = x_test.astype( np.float32) \n",
    "\n",
    "# normalize the values of image vectors to fit under 1 \n",
    "x_train /= 255 \n",
    "x_test /= 255 \n",
    "\n",
    "# convert output data into one hot encoded format \n",
    "y_train = utils.to_categorical( y_train, n_classes) \n",
    "y_test = utils.to_categorical( y_test, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.3085 - accuracy: 0.1206\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.2420 - accuracy: 0.1850\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.1590 - accuracy: 0.2777\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.0270 - accuracy: 0.3869\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.8352 - accuracy: 0.4780\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.6069 - accuracy: 0.5452\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.3922 - accuracy: 0.6043\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.2168 - accuracy: 0.6493\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0831 - accuracy: 0.6849\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.9802 - accuracy: 0.7121\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.8622 - accuracy: 0.7794\n",
      "\\ n loss: 0.8622375130653381\n",
      "\\ n accuracy: 0.7793999910354614\n"
     ]
    }
   ],
   "source": [
    "# build a sequential model \n",
    "\n",
    "model = Sequential() # the first layer has to specify the dimensions of the input vector \n",
    "model.add( Dense( units = 128, activation ='sigmoid', input_shape =( n_inputs,))) # add dropout layer for preventing overfitting \n",
    "model.add( Dropout( 0.1)) \n",
    "model.add( Dense( units = 128, activation ='sigmoid')) \n",
    "model.add( Dropout( 0.1)) # output layer can only have the neurons equal to the number of outputs \n",
    "model.add( Dense( units = n_classes, activation ='softmax')) # print the summary of our model \n",
    "model.summary() \n",
    "\n",
    "# compile the model \n",
    "model.compile( loss ='categorical_crossentropy', optimizer = SGD(), metrics =['accuracy']) \n",
    "\n",
    "# train the model \n",
    "model.fit( x_train, y_train, batch_size = batch_size, epochs = n_epochs) \n",
    "\n",
    "# evaluate the model and print the accuracy score \n",
    "\n",
    "scores = model.evaluate( x_test, y_test) \n",
    "\n",
    "print('\\ n loss:', scores[ 0]) \n",
    "\n",
    "print('\\ n accuracy:', scores[ 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
