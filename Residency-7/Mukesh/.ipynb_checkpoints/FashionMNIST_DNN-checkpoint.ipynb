{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "colab_type": "code",
    "id": "9LmtD9kcNRjE",
    "outputId": "b9db81e9-fb5e-4d6c-a354-1db0b1111143"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p5--3ZTDNO7K"
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.layers import LeakyReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tqdg3t0xNO7Q"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "xQ5lw7P1eukZ",
    "outputId": "b21665ff-57d3-47f5-cd7c-786dfd90b8f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_1 (None, 28, 28) ==> (None, 784)\n",
      "dense_3 (None, 784) ==> (None, 512)\n",
      "dense_4 (None, 512) ==> (None, 512)\n",
      "dropout_1 (None, 512) ==> (None, 512)\n",
      "dense_5 (None, 512) ==> (None, 10)\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))    #flattens the 28X28 image into 784 element array\n",
    "\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "       \n",
    "        \n",
    "\n",
    "for l in model.layers:\n",
    "    print (l.name, l.input_shape,'==>',l.output_shape)\n",
    "print()\n",
    "print (model.summary())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HPUTUQ_XNO7Y",
    "outputId": "232ce1b6-0290-4609-a390-204818dcd361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1868/1875 [============================>.] - ETA: 0s - loss: 0.5029 - accuracy: 0.8188WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5026 - accuracy: 0.8189 - val_loss: 0.4060 - val_accuracy: 0.8516\n",
      "Epoch 2/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.3754 - accuracy: 0.8642WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3754 - accuracy: 0.8642 - val_loss: 0.4153 - val_accuracy: 0.8533\n",
      "Epoch 3/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.3409 - accuracy: 0.8756WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3408 - accuracy: 0.8756 - val_loss: 0.3756 - val_accuracy: 0.8621\n",
      "Epoch 4/10\n",
      "1868/1875 [============================>.] - ETA: 0s - loss: 0.3214 - accuracy: 0.8823WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3214 - accuracy: 0.8823 - val_loss: 0.3435 - val_accuracy: 0.8748\n",
      "Epoch 5/10\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.3058 - accuracy: 0.8878WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3055 - accuracy: 0.8879 - val_loss: 0.3472 - val_accuracy: 0.8778\n",
      "Epoch 6/10\n",
      "1867/1875 [============================>.] - ETA: 0s - loss: 0.2904 - accuracy: 0.8923WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2905 - accuracy: 0.8923 - val_loss: 0.3617 - val_accuracy: 0.8759\n",
      "Epoch 7/10\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.2830 - accuracy: 0.8951WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2830 - accuracy: 0.8951 - val_loss: 0.3493 - val_accuracy: 0.8745\n",
      "Epoch 8/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.2747 - accuracy: 0.8983WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2745 - accuracy: 0.8983 - val_loss: 0.3517 - val_accuracy: 0.8737\n",
      "Epoch 9/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.2639 - accuracy: 0.9026WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2638 - accuracy: 0.9026 - val_loss: 0.3505 - val_accuracy: 0.8759\n",
      "Epoch 10/10\n",
      "1868/1875 [============================>.] - ETA: 0s - loss: 0.2569 - accuracy: 0.9044WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2569 - accuracy: 0.9043 - val_loss: 0.3519 - val_accuracy: 0.8806\n",
      "Accuracy: 88.06%\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "epochs = 10\n",
    "lrate = 0.01\n",
    "#decay = lrate/epochs\n",
    "          \n",
    "#sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'] , )\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=2, verbose=1, mode='auto')\n",
    "callback_list = [early_stopping]# [stats, early_stopping]\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32 , callbacks=callback_list)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8mRiB5leukx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sMdooUpVeuk1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FashionMNIST_DNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
