{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OJmiE27Oi6ei"
   },
   "source": [
    "# Evaluating a classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZbDqRTki6em"
   },
   "source": [
    "## Agenda\n",
    "\n",
    "- What is the purpose of **model evaluation**, and what are some common evaluation procedures?\n",
    "- What is the usage of **classification accuracy**, and what are its limitations?\n",
    "- How does a **confusion matrix** describe the performance of a classifier?\n",
    "- What **metrics** can be computed from a confusion matrix?\n",
    "- How can you adjust classifier performance by **changing the classification threshold**?\n",
    "- What is the purpose of an **ROC curve**?\n",
    "- How does **Area Under the Curve (AUC)** differ from classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7s3dkBQdi6eq"
   },
   "source": [
    "## Review of model evaluation\n",
    "\n",
    "- Need a way to choose between models: different model types, tuning parameters, and features\n",
    "- Use a **model evaluation procedure** to estimate how well a model will generalize to out-of-sample data\n",
    "- Requires a **model evaluation metric** to quantify the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGZvMHl7i6es"
   },
   "source": [
    "### Model evaluation procedures\n",
    "\n",
    "1. **Training and testing on the same data**\n",
    "    - Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
    "2. **Train/test split**\n",
    "    - Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
    "    - Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
    "    - Useful due to its speed, simplicity, and flexibility\n",
    "3. **K-fold cross-validation**\n",
    "    - Systematically create \"K\" train/test splits and average the results together\n",
    "    - Even better estimate of out-of-sample performance\n",
    "    - Runs \"K\" times slower than train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1MW1U2lzi6eu"
   },
   "source": [
    "### Model evaluation metrics\n",
    "\n",
    "- **Regression problems:** Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "- **Classification problems:** Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DkLva0OAi6ew"
   },
   "source": [
    "## Classification accuracy\n",
    "\n",
    "[Pima Indian Diabetes dataset](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes) from the UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVMjzFT-i6ey"
   },
   "outputs": [],
   "source": [
    "# read the data into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "pima = pd.read_csv('pima-indians-diabetes.data', header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PrAWoQmi6e5",
    "outputId": "2367aa57-21f0-491e-9545-5dc930861432"
   },
   "outputs": [],
   "source": [
    "# print the first 5 rows of data\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lMaWvfsBi6e-"
   },
   "source": [
    "**Question:** Can we predict the diabetes status of a patient given their health measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPWHkyeOi6fA"
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['pregnant','glucose', 'bp', 'skin', 'insulin', 'bmi', 'age']\n",
    "X = pima[feature_cols]\n",
    "y = pima.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-oNiIDei6fD"
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjfqkUkDi6fJ",
    "outputId": "8b584e14-186f-4450-8f05-9c0aefde9a30"
   },
   "outputs": [],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver='lbfgs')   \n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5_hPUuei6fN"
   },
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-DiaR4Gi6fQ"
   },
   "source": [
    "**Classification accuracy:** percentage of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojyb8anSi6fS",
    "outputId": "25c93a9c-af49-4097-d32b-0bcfce353b5c"
   },
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQXP2bGwi6fV"
   },
   "source": [
    "## Confusion matrix\n",
    "\n",
    "Table that describes the performance of a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oK1h5ab-i6fW",
    "outputId": "b123865d-f345-45d2-afa6-519c09d7ae06"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVxWdd_9i6fa"
   },
   "source": [
    "- Every observation in the testing set is represented in **exactly one box**\n",
    "- It's a 2x2 matrix because there are **2 response classes**\n",
    "- The format shown here is **not** universal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qNz5ptAdi6fb"
   },
   "source": [
    "**Basic terminology**\n",
    "\n",
    "- **True Positives (TP):** we *correctly* predicted that they *do* have diabetes\n",
    "- **True Negatives (TN):** we *correctly* predicted that they *don't* have diabetes\n",
    "- **False Positives (FP):** we *incorrectly* predicted that they *do* have diabetes (a \"Type I error\")\n",
    "- **False Negatives (FN):** we *incorrectly* predicted that they *don't* have diabetes (a \"Type II error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vs0AABmzi6fc"
   },
   "source": [
    "## Metrics computed from a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJEOlyZCi6fe"
   },
   "source": [
    "**Classification Accuracy:** Overall, how often is the classifier correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZJMdG7gi6ff",
    "outputId": "c97bbfd3-9ecf-457d-8490-b9e64b204ad3"
   },
   "outputs": [],
   "source": [
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AnhhAoSgi6fl"
   },
   "source": [
    "**Classification Error:** Overall, how often is the classifier incorrect?\n",
    "\n",
    "- Also known as \"Misclassification Rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btSmN1pWi6fm",
    "outputId": "80475b54-051a-4934-d946-327d2e4ed29b"
   },
   "outputs": [],
   "source": [
    "print((FP + FN) / float(TP + TN + FP + FN))\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRHoEZJSi6fp"
   },
   "source": [
    "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
    "\n",
    "- How \"sensitive\" is the classifier to detecting positive instances?\n",
    "- Also known as \"True Positive Rate\" or \"Recall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NB09r_9Di6fq",
    "outputId": "45827109-b314-495a-f756-cfd24bdf2e41"
   },
   "outputs": [],
   "source": [
    "print(TP / float(TP + FN))\n",
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoMMUFAEi6fz"
   },
   "source": [
    "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
    "\n",
    "- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKoGiEaYi6f1",
    "outputId": "297023a7-9949-4dd1-be4d-17ac44e424a4"
   },
   "outputs": [],
   "source": [
    "print(TN / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ou4KqnHei6f6"
   },
   "source": [
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ma-dmG-5i6f8",
    "outputId": "8465f0e4-6c3d-45d9-a1a1-16d75813f791"
   },
   "outputs": [],
   "source": [
    "print(FP / float(TN + FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THS0BplYi6gJ"
   },
   "source": [
    "**Precision:** When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "- How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_k645aAi6gL",
    "outputId": "539856b7-ef48-4e8b-ecf5-3d35add4981f"
   },
   "outputs": [],
   "source": [
    "print(TP / float(TP + FP))\n",
    "print(metrics.precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4AfFcqgTi6gO"
   },
   "source": [
    "## Adjusting the classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fOVpy3yi6gP",
    "outputId": "c3599ffa-cc58-419c-b995-7a9fd85c03cb"
   },
   "outputs": [],
   "source": [
    "# print the first 10 predicted responses\n",
    "logreg.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ueo3Zt1i6gZ",
    "outputId": "5c793cc8-ffae-4450-ad12-e7d4bbeb781e"
   },
   "outputs": [],
   "source": [
    "# print the first 10 predicted probabilities of class membership\n",
    "logreg.predict_proba(X_test)[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-GCx0o4i6gn",
    "outputId": "aeb21714-109a-446f-d396-15409bfda8a2"
   },
   "outputs": [],
   "source": [
    "# print the first 10 predicted probabilities for class 1  (diabetics)\n",
    "logreg.predict_proba(X_test)[0:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FRatkInWi6gu"
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilities for diabetic class \n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wnioxn-hi6gy"
   },
   "source": [
    "**Decrease the threshold** for predicting diabetes in order to **increase the sensitivity** of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XR3TgvJti6gz"
   },
   "outputs": [],
   "source": [
    "# predict diabetes if the predicted probability is greater than 0.3\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize([y_pred_prob], 0.3)[0]  # deciding the class of the 1st 10 records based on new threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLvEoAZ7i6g7",
    "outputId": "bbb96b32-c10a-4c51-9b02-7355e7493f2e"
   },
   "outputs": [],
   "source": [
    "# print the first 10 predicted probabilities\n",
    "y_pred_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzMhbTRJi6g_",
    "outputId": "3beb13c6-2934-4667-a32d-caf2e9d95e26"
   },
   "outputs": [],
   "source": [
    "# print the first 10 predicted classes with the lower threshold. Note the change in class...\n",
    "# with threshold of .5 (default) , the first data point would belong to 0 class i.e. non-diabetic \n",
    "y_pred_class[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTbRe1bhi6hE",
    "outputId": "c8096640-b07c-4f7c-c92f-72b7dcea813a"
   },
   "outputs": [],
   "source": [
    "# previous confusion matrix (default threshold of 0.5)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlyFZxRwi6hI",
    "outputId": "1affbfd2-ab34-461d-9e98-f8c29d7c61e2"
   },
   "outputs": [],
   "source": [
    "# new confusion matrix (threshold of 0.3)\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxnBKQx_i6hL",
    "outputId": "ea629e10-2a77-49d4-ce4f-4c02d79a34e2"
   },
   "outputs": [],
   "source": [
    "# sensitivity has increased (used to be 0.24)\n",
    "print(46 / float(46 + 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqUMI1wci6hQ",
    "outputId": "ea59f35f-30ed-4e54-d6b5-49ed22e0268a"
   },
   "outputs": [],
   "source": [
    "# specificity has decreased (used to be 0.91)\n",
    "print(80 / float(80 + 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ueVMQXgi6hU"
   },
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- **Threshold of 0.5** is used by default (for binary problems) to convert predicted probabilities into class predictions\n",
    "- Threshold can be **adjusted** to increase sensitivity or specificity\n",
    "- Sensitivity and specificity have an **inverse relationship**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWiKuPfDi6hV"
   },
   "source": [
    "## ROC Curves and Area Under the Curve (AUC)\n",
    "\n",
    "**Question:** Wouldn't it be nice if we could see how sensitivity and specificity are affected by various thresholds, without actually changing the threshold?\n",
    "\n",
    "**Answer:** Plot the ROC curve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5i588exi6hW",
    "outputId": "f7628ba5-35e0-4413-c2d4-3de62aa89f54"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for diabetes classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OeLeZi2mi6ha"
   },
   "source": [
    "- ROC curve can help you to **choose a threshold** that balances sensitivity and specificity in a way that makes sense for your particular context\n",
    "- You can't actually **see the thresholds** used to generate the curve on the ROC curve itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDJfrh0qi6hb"
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a threshold and prints sensitivity and specificity\n",
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtcufeRyi6hd",
    "outputId": "bd94f043-3cdf-4c6c-9598-02a8866ecf40"
   },
   "outputs": [],
   "source": [
    "evaluate_threshold(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAA9MqUKi6hh",
    "outputId": "b3e879b5-7d07-4cc9-bde6-dbe2088fc3a4"
   },
   "outputs": [],
   "source": [
    "evaluate_threshold(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwuDr6G6i6hk"
   },
   "source": [
    "AUC is the **percentage** of the ROC plot that is **underneath the curve**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73J7WTpFi6hl",
    "outputId": "6b8bf2a2-73e3-40dd-b1e9-4f931829a9a6"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k21NUxdci6hn"
   },
   "source": [
    "- AUC is useful as a **single number summary** of classifier performance.\n",
    "- If you randomly chose one positive and one negative observation, AUC represents the likelihood that your classifier will assign a **higher predicted probability** to the positive observation.\n",
    "- AUC is useful even when there is **high class imbalance** (unlike classification accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tt_h3VvEi6ho",
    "outputId": "d1e92c09-6a73-4f4e-d754-b7e481e32871"
   },
   "outputs": [],
   "source": [
    "# calculate cross-validated AUC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cig1_xRbi6hr"
   },
   "source": [
    "**Confusion matrix advantages:**\n",
    "\n",
    "- Allows you to calculate a **variety of metrics**\n",
    "- Useful for **multi-class problems** (more than two response classes)\n",
    "\n",
    "**ROC/AUC advantages:**\n",
    "\n",
    "- Does not require you to **set a classification threshold**\n",
    "- Still useful when there is **high class imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "segIC8pSi6hs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "classification_metrics-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
